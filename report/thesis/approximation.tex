\chapter{Over-Approximation and Under-Approximation}\label{chap:OT-UT}
\section{Approximation Theory}
\begin{comment}
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_j \psi_j(x_1,\cdots,x_n)$, 
%\exists x_1 \ldots x_n. (\underbrace{\bigwedge \limits_i x_i \in I_i}_{I}) \wedge 
%                       (\underbrace{\bigwedge \limits_j \psi_j(x_1,\cdots,x_n)}_{P})
where $\psi_j(x_1,\cdots,x_n)$ is an atomic formula. 
%
$F$ is equivalnet to 
$\exists x_1 \ldots x_n. (\bigwedge \limits_i x_i \in I_i) \wedge (\bigwedge \limits_j \psi_j(x_1,\cdots,x_n))$, 
and we call $\bigwedge \limits_i x_i \in I_i$ {\em interval constraints}, and 
we refer $\bigwedge \limits_j \psi_j(x_1,\cdots,x_n)$ by $\psi(x_1,\cdots,x_n)$. 
Initially, interval constraints have a form of the conjunction $\bigwedge \limits_i x_i \in I_i$, 
and later by refinement, $x_i \in I_i$ is decomposed into a clause $\bigvee_j x_i \in I_{i_j}$, 
which makes a CNF. 

As an SMT (SAT modulo theory) problem, 
boolean variables are assigned to each $x_i \in I_{i_j}$, 
and truth assignments is produced by a SAT solver, 
which are proved or disproved by a background theory $T$ whether it satisfies $\psi(x_1,\cdots,x_n)$. 

As notational convention, $m$ (the lower case) denotes 
a variable assignments on $x_i$'s, and 
$M$ (the upper case) denotes a truth assignment on $x_i \in I_{i_j}$'s. 
We write $m \in M$ when an instance $m = \{ x_i \leftarrow c_i \}$ satisfies 
all $c_i \in I_{i_j}$ that are assigned true by $M$. 

We assume {\em very lazy theory learning}~\cite{dpll}, and 
a backend theory $T$ is applied only for a full truth assignment $M$. 
%We regard $M$ as a conjunction $\bigwedge \limits_i x_i \in I_{i_j}$. 
\begin{itemize}
\item If an instance $m$ satisfies $\psi(x_1,\cdots,x_n)$, we denote $m \models_T \psi(x_1,\cdots,x_n)$. 
\item If each instance $m$ with $m \in M$ satisfies $\psi(x_1,\cdots,x_n)$, 
we denote $M \models_T \psi(x_1,\cdots,x_n)$. 
\end{itemize}
\end{comment}

\begin{comment}
\begin{definition} \label{def:app}
Let $F = \exists x_1 \in I_1 \cdots x_n \in I_n. \psi(x_1,\cdots,x_n)$. 
For a truth assignment on $M$, $F$ is 
\begin{itemize}
\item $T$-valid if $M \models_T \psi(x_1,\cdots,$ $x_n)$, 
\item $T$-satisfiable ($T$-SAT) if $m \models_T \psi(x_1,\cdots,x_n)$ 
for some $m \in M$, and 
\item $T$-unsatisfiable ($T$-UNSAT) if $M \models_T \neg \psi(x_1,\cdots,x_n)$. 
\end{itemize}
If $T$ is clear from the context, we simply say valid, satisfiable, and unsatisfiable. 
\end{definition}
\end{comment}

%%%%%%%%%%%%%
\suppress{
Then, Fig. \ref{fig:T_result} illustrates Definition~\ref{def:app}. 
\begin{figure} [ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
  \includegraphics[height=1.8in,width=1.9in]{T_result.eps}
\caption{Results of a target constraint $F$ in a theory $T$}
\label{fig:T_result}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
   \includegraphics[height=2.2in,width=2.3in]{frame_app.eps}
\caption{{\bf raSAT} loop}
\label{fig:frame}
\end{minipage}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{definition} \label{def:ApproxTheory}
Let $T, T'$ be $\Sigma$-theories and $\varphi$ be any $\Sigma$-formula. 
\begin{itemize}
\item $T'$ is an {\em over-approximation theory} (of $T$) 
iff $T'$-UNSAT of $\varphi$ implies $T$-UNSAT of $\varphi$.
\item $T'$ is an {\em under-approximation theory} (of $T$)
iff $T'$-SAT of $\varphi$ implies $T$-SAT of $\varphi$. 
\end{itemize}
\end{definition}

\begin{theorem}
If $T_O$ be an over-approximation theory of $T$, then for any $\Sigma$-formula $\varphi$: $\varphi$ is $T_O$-VALID $\implies \varphi$ is $T$-VALID.
\end{theorem}

\begin{proof}
$\varphi$ is $T_O$-VALID $\implies$ $\neg\varphi$ is $T_O$-UNSAT (Lemma \ref{lemma:theory-valid-unsat}) $\implies \neg\varphi$ is $T$-UNSAT (Definition \ref{def:ApproxTheory}) $\implies \varphi$ is T-VALID (Lemma \ref{lemma:theory-valid-unsat})
\end{proof}

%Note that $O.T$-valid can be regarded as $U.T$, since $O.T$-valid implies $T$-valid, thus $T$-SAT. 
A typical ICP applies $O.T$ only as an interval arithmetic. 
Later in Section~\ref{sec:approximation}, we will instantiate interval arithmetic as $O.T$. 
Adding to $O.T$-valid, {\bf raSAT} introduce testing as $U.T$ to accelerate SAT detection. 

\section{Interval Arithmetic as an Over-Approximation Theory}\label{sec:IA}
\subsection{Real Intervals}
We adopt the definition of real intervals from \cite{Hickey:2001:IAP:502102.502106}:
\begin{definition}\cite{Hickey:2001:IAP:502102.502106}
Let $a$ and $b$ be reals such that $a \le b$.
\begin{center}
\begin{tabular}{ r c l }
  $\langle a, b \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | a \le x \le b\}$ \\
  $\langle -\infty, b \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | x \le b\}$ \\
  $\langle a, +\infty \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | a \le x\}$ \\  
  $\langle -\infty, +\infty \rangle$ & $\overset{def}{=}$ & $\mathbb{R}$ \\  
\end{tabular}
\end{center}
\end{definition}
All intervals in this definition can be summarized by $\langle a, b \rangle$ where $a, b \in \mathbb{R} \cup \{-\infty, +\infty\}$ and $a \le b$ with the assumption that $\forall c \in \mathbb{R}-\infty < c < \infty$. Furthermore,\citet{Hickey:2001:IAP:502102.502106} also defined arithmetic operations for $\mathbb{R} \cup \{-\infty, +\infty\}$ which is summarized in Table ~.

\begin{tabular}{c||*{5}{c|}}
$x + y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$-\infty$&$-\infty$&$-\infty$&$-\infty$&$\bot$\\\hline
$NR$ &&NR&NR&$\mathbb{R}$&$+\infty$\\\hline
$0$&&&0&PR&$+\infty$\\\hline
$PR$ &&&&PR&$+\infty$\\\hline
$+\infty$ &&&&&$+\infty$\\\hline
\end{tabular}
\quad
\begin{tabular}{c||*{5}{c|}}
$x - y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$\bot$&$+\infty$&$+\infty$&$+\infty$&$+\infty$\\\hline
$NR$ &$-\infty$&$\mathbb{R}$&PR&PR&$+\infty$\\\hline
$0$&$-\infty$&NR&0&PR&$+\infty$\\\hline
$PR$ &$-\infty$&NR&NR&$\mathbb{R}$&$+\infty$\\\hline
$+\infty$ &$-\infty$&$-\infty$&$-\infty$&$-\infty$&$\bot$\\\hline
\end{tabular}
\newline
\vspace*{1 cm}
\newline
\begin{tabular}{c||*{5}{c|}}
$x \times y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$+\infty$&$+\infty$&$\bot$&$-\infty$&$-\infty$\\\hline
$NR$ &&PR&0&NR&$-\infty$\\\hline
$0$&&&0&0&$\bot$\\\hline
$PR$ &&&&PR&$+\infty$\\\hline
$+\infty$ &&&&&$+\infty$\\\hline
\end{tabular}

\begin{definition} \label{def:real_intervals}
The set of all real intervals $\mathbb{I}$ is defined as $\mathbb{I} = \{\langle a, b \rangle | a, b \in \mathbb{R} \cup \{-\infty, +\infty\} \text{ and } a \le b \}$.
\end{definition}

\subsection{Interval Arithmetic as an Over-Approximation Theory}
A model $M^p_{IA} = (U^p_{IA}, I^p_{IA})$ over intervals contains a set of all intervals $U^p_{IA} = \{\langle l, h\rangle | l, h \in \mathbb{R} \cup \{-\infty, +\infty\} \text{ and } l \le h\}$ and a map $I^p_{IA}$ that satisfies the following conditions.
\begin{enumerate}
\item $I^p_{IA}(Real) = U^p_{IA}$
\item $\forall p \in P^p$; $I^p_{IA}(p)= U^p_{IA} \times U^p_{IA} \mapsto \{0, 1\}$ where $I^p_{IA}(p)(i_1, i_2) = i_1 \; p_{IA} \; i_2$. The definition of $ p_{IA}$ is as follow:
\begin{itemize}
\item $\langle l_1, h_1\rangle  \succ_{IA} \langle l_2,  h_2\rangle  = \left\{ 
  \begin{array}{c l}
    1 & \quad \text{if } l_1 > h_2\\
    0 & \quad \text{if } h_1 \le l_2 \\
  \end{array} \right.$
\item $\langle l_1, h_1\rangle  \prec_{IA} \langle l_2,  h_2\rangle  = \left\{ 
  \begin{array}{c l}
    1 & \quad \text{if } h_1 < l_2\\
    0 & \quad \text{if } l_1 \ge h_2 \\
  \end{array} \right.$
\item $i_1 \succeq_{IA} i_2 = 1 - (i_1 \prec_{IA} i_2)$
\item $i_1 \preceq_{IA} i_2 = 1 - (i_1 \succ_{IA} i_2)$
\item $i_1 \approx_{IA} i_2 = min (i_1 \succeq_{IA} i_2, i_1 \preceq_{IA} i_2)$
\item $i_1 \not\approx_{IA} i_2 = 1 - (i_1 \approx_{IA} i_2)$
\end{itemize}
\item $\forall f \in F^p \setminus \{\mathbf{1}\}$; $I^p_{IA}(f) = U^p_{IA} \times U^p_{IA} \mapsto U^p_{IA}$ such that $ I^p_{IA}(f)(i_1, i_2)= i_1 \; f_{IA} \; i_2$ where $f_{IA}$ satisfies the following properties:
\begin{itemize}
\item $i_1 \oplus_{IA} i_2 \supseteq \{r_1 + r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\item $i_1 \ominus_{IA} i_2 \supseteq \{r_1 - r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\item $i_1 \otimes_{IA} i_2 \supseteq \{r_1 * r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\end{itemize}
\item $I^p_{IA}(\mathbf{1}) = \langle 1,1\rangle $
\item $\forall v \in V$; $I^p_{IA} \in U^p_{IA}$
\end{enumerate}
Theory $T^p_{IA} = \{M^p_{IA}| M^p_{IA} \text{ is a model over intervals}\}$. Each model differs to another by the mapping from variables to intervals. As a consequence, one assignment from variables to intervals can be used to describe an model. An assignment $\{v \mapsto i \in \mathbb{I} | v \in V\}$ and an interval constraint $\bigwedge\limits_{v \in V} v \in i$ are equivalent in terms of the set of assignments from variables to real numbers. So by abusing notation, for a constraint of the form $\Pi = \bigwedge\limits_{v \in V} v \in i$, we denote $\Pi^p_{IA}$ as a model of interval arithmetics for polynomial constraints. By definition, $\{\Pi^p_{IA}\}$ represents a sub-theory of $T^p_{IA}$.

\begin{lemma} \label{lemma:IA-R-OP}
Let $M^p_{IA} = (U^p_{IA}, I^p_{IA})$ be a model over intervals, we have:
\begin{center}
$\forall i_1, i_2 \in U^p_{IA}; \forall r_1 \in i_2, r_2 \in i_2; \forall p \in P^p (i_1 \; p_{IA} \; i_2 = 0 \implies \text{ not } (r_1 \; p_\mathbb{R} \; r_2))$
\end{center}
\end{lemma}

\begin{proof}
Let $i_1 = \langle l_1, h_1\rangle $ and $i_2 = \langle l_2, h_2\rangle $ where $l_1 \le h_1$ and $l_2 \le h_2$. We have: 
\begin{itemize}
\item $r_1 \in i_1 \implies l_1 \le r_1 \le h_1$. 
\item $r_2 \in i_2 \implies l_2 \le r_2 \le h_2$. 
\end{itemize}
Suppose  that $i_1 \; p_{IA} \; i_2 = 0 $, we need to show $not \; (r_1 \; p_\mathbb{R} \; r_2)$ by considering all the possible cases of $p$:
\begin{enumerate}
\item If $p$ is $\succ$, the we have $\langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle  = 0  \implies h_1 \le l_2 \implies r_1 \le r_2$ (because $r_1 \le h_1$ and $l_2 \le r_2$) $\implies not \; (r_1 > r2) \implies not \; (r_1 \succ_\mathbb{R} r_2)$.
\item If $p$ is $\prec$, the we have $\langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle  = 0  \implies l_1 \ge h_2 \implies r_1 \ge r_2$ (because $r_1 \ge l_1$ and $r_2 \le h_2$) $\implies not \; (r_1 < r_2) \implies not \; (r_1 \prec_\mathbb{R} r_2)$.
\item If $p$ is $\succeq$, the we have $\langle l_1, h_1\rangle  \succeq_{IA} \langle l_2, h_2\rangle  = 0  \implies {1 -  (\langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle ) = 0}  \implies \langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle  = 1 \implies h_1 < l_2 \implies r_1 < r_2$ (because $r_1 \le h_1$ and $r_2 \ge l_2$) $\implies not \; (r_1 \ge r_2) \implies not \; (r_1 \succeq_\mathbb{R} r_2)$.
\item If $p$ is $\preceq$, the we have $\langle l_1, h_1\rangle  \preceq_{IA} \langle l_2, h_2\rangle  = 0  \implies {1 - (\langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle ) = 0}  \implies \langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle  = 1 \implies l_1 > h	_2 \implies r_1 > r_2$ (because $r_1 \ge l_1$ and $r_2 \le h_2$) $\implies not \; (r_1 \le r_2) \implies not \; (r_1 \preceq_\mathbb{R} r_2)$.
\item If $p$ is $\approx$, the we have $i_1 \approx_{IA} i_2 = 0  \implies min(i_1 \succeq_{IA} i_2 , i_1 \preceq_{IA} i_2) = 0  \implies {i_1 \succeq_{IA} i_2 = 0}  \text{ or } i_1 \preceq_{IA} i_2 = 0  \implies r_1 < r_2 \text{ or } r_1 > r_2$ (as the third and fourth case of this proof) $\implies not \; (r_1 = r_2) \implies not \; (r_1 \approx_\mathbb{R} r_2)$.
\item \sloppy If $p$ is $\not\approx$, the we have $i_1 \not\approx_{IA} i_2 = 0  \implies 1 - (i_1 \approx_{IA} i_2) = 0  \implies {min(i_1 \succeq_{IA} i_2, i_1 \preceq_{IA} i_2) = 1} \implies i_1 \succeq_{IA} i_2 = 1$ and $i_1 \preceq_{IA} i_2 = 1   \implies 1 - (i_1 \prec_{IA} i_2) = 1 \text{ and } 1 - (i_1 \succ_{IA} i_2) = 1  \implies {i_1 \prec_{IA} i_2 = 0  \text{ and } i_1 \succ_{IA} i_2 = 0}  \implies {r_1 \ge r_2} \text{ and } {r_1 \le r_2}$ (as the first and second case of this proof) $\implies r_1 = r_2 \implies not \; (r_1 \not= r_2) \implies not \; (r_1 \not\approx_\mathbb{R} r_2)$.
\end{enumerate}
\end{proof}

\begin{lemma} \label{lemma:IA-OT}
Let $\Pi = \bigwedge\limits_{v \in V}v \in i$ with $i \in \mathbb{I}$, we have ${\forall t \in TERM^p \; \forall M^p_\mathbb{R} \in \Pi^p_\mathbb{R} \; t^{M^p_\mathbb{R}} \in t^{\Pi^p_{IA}}}$.
\end{lemma}

\begin{proof}
Proof is done by induction on structure of term.
Let $t \in TERM^p$ and $M^p_\mathbb{R} = (\mathbb{R}, I^p_\mathbb{R}) \in \Pi^p_\mathbb{R}$
\begin{enumerate}
\item If $t = v \in V$, then $t^{M^p_\mathbb{R}} = I^p_\mathbb{R}(v) \in \Pi(v)$ because $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$. In addition, $t^{\Pi^p_{IA}} = \Pi^p_\mathbb{R}$.
\item If $t = \mathbf{1}$, then $t^{M^p_\mathbb{R}} = 1 \in \langle 1, 1\rangle  = t^{\Pi^p_{IA}}$
\item If $t = t_1 \; f \; t_2$ for some $f \in F^p \setminus \{0, 1\}$

$t^{M^p_\mathbb{R}} = t_1^{M^p_\mathbb{R}} \; f_\mathbb{R} \; t_1^{M^p_\mathbb{R}}$

$t^{\Pi^p_{IA}} = t_1^{\Pi^p_{IA}} \; f_{IA} \; t_2^{\Pi^p_{IA}}$

By induction hypothesis, we have $t_1^{M^p_\mathbb{R}} \in t_1^{\Pi^p_{IA}}$ and $t_1^{M^p_\mathbb{R}} \in t_2^{\Pi^p_{IA}}$. In addition, due to the properties of $f_{IA}$: $t_1^{M^p_\mathbb{R}} \; f_\mathbb{R} \; t_1^{M^p_\mathbb{R}} \in t_1^{\Pi^p_{IA}} \; f_{IA} \; t_2^{\Pi^p_{IA}}$, or $t^{M^p_\mathbb{R}} \in t^{\Pi^p_{IA}}$ 
\end{enumerate}
\end{proof}

\begin{theorem} \label{theorem:IA-OverAprox}
If $\Pi = \bigwedge\limits_{v \in V}v \in i$ with $i \in \mathbb{I}$ is a map from variables to intervals, then $\{\Pi^p_{IA}\}$ is an over-approximation of $\Pi^p_\mathbb{R}$.
\end{theorem}

\begin{proof}
In order to prove Theorem ~\ref{theorem:IA-OverAprox}, we need to prove that $\forall \varphi^p (\varphi^p$ is $\{\Pi^p_{IA}\}$-UNSAT $\implies \varphi^p$ is $\Pi^p_\mathbb{R}$-UNSAT). 

Given an $\Sigma^p$-formula $\varphi^p$ and suppose that $\varphi^p$ is $\{\Pi^p_{IA}\}$-UNSAT.
Suppose $\varphi^p$ is not $\Pi^p_\mathbb{R}$-UNSAT, that means it is either  $\Pi^p_\mathbb{R}$-SAT or  $\Pi^p_\mathbb{R}$-VALID. In either case, there exist at least a model $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$ such that $\models_{M^p_\mathbb{R}} \varphi^p \iff (\varphi^p)^{M^p_\mathbb{R}}= true$.
\begin{enumerate}
\item \sloppy If $\varphi^p = p(t_1, t_2)$ for some $p \in P^p$, then $(\varphi^p)^{M^p_\mathbb{R}}= true \implies t_1^{M^p_\mathbb{R}} \; p_\mathbb{R} \; t_2^{M^p_\mathbb{R}}$. 

On the other hand, $\varphi^p$ is $\{\Pi^p_{IA}\}$-UNSAT $\implies (\varphi^p)^{\Pi^p_{IA}} = 0  \implies t_1^{\Pi^p_{IA}} \; p_{IA} \; t_2^{\Pi^p_{IA}} = 0 $. In addition, because $t_1^{M^p_\mathbb{R}} \in t_1^{\Pi^p_{IA}}$ and $t_2^{M^p_\mathbb{R}} \in t_2^{\Pi^p_{IA}}$ (Lemma ~\ref{lemma:IA-OT}), ${t_1^{\Pi^p_{IA}} \; p_{IA} \; t_2^{\Pi^p_{IA}} = 0}  \implies \neg(t_1^{M^p_\mathbb{R}} \; p_\mathbb{R} \; t_2^{M^p_\mathbb{R}})$ (Lemma ~\ref{lemma:IA-R-OP}). This is a contradiction. As the result, $\varphi^p$ must be $\Pi^p_\mathbb{R}$-UNSAT.
\item If $\varphi^p = \varphi^p_1 \wedge \varphi^p_2$, then we have $\varphi^p$ is  $\{\Pi^p_{IA}\}$-UNSAT $\implies \not\models_{\Pi^p_{IA}}(\varphi^p_1 \wedge \varphi^p_2) \implies (\varphi^p_1 \wedge \varphi^p_2)^{\Pi^p_{IA}} = 0  \implies (\varphi^p_1)^{\Pi^p_{IA}} \wedge (\varphi^p_2)^{\Pi^p_{IA}} = 0  \implies (\varphi^p_1)^{\Pi^p_{IA}} = 0 $ and $(\varphi^p_2)^{\Pi^p_{IA}} = 0 $. By induction hypothesis, $\varphi^p_1$ and $\varphi^p_2$ are $\Pi^p_\mathbb{R}$-UNSAT $\implies \forall M^p_\mathbb{R} \in \Pi^p_\mathbb{R} \; \not\models_{M^p_{IA}} \varphi^p_1$ and $\forall M^p_\mathbb{R} \in \Pi^p_\mathbb{R} \; \not\models_{M^p_{IA}} \varphi^p_2 \implies \forall M^p_\mathbb{R} \in \Pi^p_\mathbb{R} \; \not\models_{M^p_{IA}} (\varphi^p_1 \wedge \varphi^p_2) \implies \varphi^p_1 \wedge \varphi^p_2$ is $\Pi^p_\mathbb{R}$-UNSAT.
\end{enumerate}
\end{proof}

\section{Testing as an Under-Approximation Theory}
\begin{definition}
Let $T^p \subseteq T^p_\mathbb{R}$ be a sub-theory of real numbers. Any sub-theory $T^p_T$ of $T^p$, i.e. $T^p_T \subseteq T^p$ is call a theory of testing with respect to $T^p$.
\end{definition}

\begin{theorem}
If $T^p_T$ is a theory of testing w.r.t $T^p$, $T^p_T$ is an under-approximation of $T^p$.
\end{theorem}

\begin{proof}
Let $\varphi^p$ is a $\Sigma^p$-formula and suppose it is $T^p_T$-SAT. We need to prove $\varphi^p$ is $T^p$-SAT. We have $\varphi^p$ is $T^p_T$-SAT $\implies \exists M^p \in T^p_T \; \models_{M^p} \varphi^p \implies \exists M^p \in T^p \; \models_{M^p} \varphi^p$ {(because $T^p_T \subseteq T^p$)} $\implies \varphi^p$ is $T^p$-SAT.
\end{proof}

Given a theory $T^p$, we randomly select a number of its models to form a theory of testing $T^p_T$ w.r.t $T^p$.

\section{raSAT Loop}
In other word, each model can be represented by an assignment of one real number to each variable. 
State of search procedure contains  $(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)$ where 
\begin{itemize}
\item $\Pi$ is the interval constraint.
\item $\varphi$ represents the polynomial constraint.
\item $\mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in i_i$ with $i_i \in \mathbb{I}$ is the result of DPLL procedure on $\Pi$.
\item $\varphi^V$ contains the constraints that are valid under over-approximation.
\item $\varphi^U$ is the set of constraints which are UNKNOWN under over-approximation.
\item $\varepsilon$ indicates the threshold to stop decomposing intervals.
\item $\tau$ is a flag to mark whether the threshold of intervals has been reached.
\end{itemize}
The transition rules are described in Table ~\ref{tab:transition-rules}. Figure ~\ref{fig:smt-design} illustrates the transition system. 

\begin{table*}[t]
  \centering
  \begin{tabular}{ll}
  \hline\\
  \large 
  $\frac{\Pi \models_{SAT} \bot}{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \bot) \to UNSAT}$ \tiny $\Pi$\_UNSAT\_UNSAT \\\\
  \large 
  $\frac{\Pi \models_{SAT} \bot}{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \top) \to UNKNOWN}$ \tiny $\Pi$\_UNSAT\_UNKNOWN \\\\
  \large 
  $\frac{\Pi \models_{SAT} \mathring{\Pi} \quad \mathring{\Pi}' = flattern(\mathring{\Pi})}{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi, \varphi, \mathring{\Pi}', \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny $\Pi$\_SAT\\\\
  \large
  $\frac{\mathring{\Pi} \not= \emptyset \quad   \varphi^V \wedge \varphi^U = \varphi \quad \varphi^V \text{ is }  \{\mathring{\Pi}^p_{IA}\}\text{-VALID}}{(\Pi, \varphi, \mathring{\Pi}, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)}$ \tiny IA\_SAT \\\\  
  \large 
  $\frac{\varphi^V = \varphi}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to SAT}$ \tiny IA\_VALID \\\\
  \large 
  $\frac{\mathring{\Pi} \not= \emptyset \quad \varphi^U \not= \emptyset \quad \varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-SAT}}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to SAT}$ \tiny TEST\_SAT \\\\
  \large     
  $\frac{\varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-UNSAT} \quad \mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle \quad \forall i (h_i - l_i < \varepsilon)}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to (\Pi \wedge \neg \mathring{\Pi}, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \top)}$ \tiny THRESHOLD \\\\
  \normalsize 
  $\frac{\varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-UNSAT} \quad \mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle \quad \exists j(h_j - l_j > \varepsilon) \quad l_j < d \in \mathbb{R} < h_j \quad I_j = v_j \in \langle l_j, h_j \rangle \quad I_{j1} = v_j \in \langle l_j, d\rangle \quad I_{j2} = v_j \in \langle d, h_j \rangle}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to (\Pi \wedge (\neg I_j \vee I_{j1} \vee I_{j2}) \wedge (I_j \vee \neg I_{j1}) \wedge (I_j \vee \neg I_{j2}) \wedge (\neg I_{j1} \vee \neg I_{j2}), \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny REFINE \\\\
  \large 
  $\frac{\mathring{\Pi} \not= \emptyset \quad \varphi \text{ is }  \{\mathring{\Pi}^p_{IA}\}\text{-UNSAT}}{(\Pi, \varphi, \mathring{\Pi}, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi \wedge \neg\mathring{\Pi}, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny IA\_UNSAT \\\\
  \hline\\
  \end{tabular}
  \caption{Transition rules}\label{tab:transition-rules}
\end{table*}

\begin{figure}[ht]
%\begin{minipage}[b]{1.0\linewidth}
\centering
\includegraphics[width=\textwidth]{smt-design.png} 
\caption{\textbf{raSAT} design} 
\label{fig:smt-design} 
%\end{minipage}
\end{figure}

\begin{theorem} \label{theorem:terminating}
Starting with state $\Pi, \varphi, \emptyset, \emptyset, \varepsilon, \tau$, if $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ and $\{(x_1, x_2, \cdots) | \models_{\theta^I} \Pi, \theta = \{v_1 \mapsto x_1, v_2 \mapsto x_2, \cdots\} \}$ is bounded, raSATloop terminates.
\end{theorem}

\begin{proof}
In the worst case, all the interval will be decomposed into smallest boxes with size of $\varepsilon$ whose number are bounded to $\frac{h_1 - l_1}{\varepsilon}\frac{h_2 - l_2}{\varepsilon}\cdots$ (the number of variables in one polynomial constraint is also bounded). As a result, raSATloop terminates after checking all of these boxes.
\end{proof}

\section{Soundness - Completeness}
\subsection{Soundness}
\begin{theorem}
Let $(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)$ be any state of our system, then the following properties are invariants:
\begin{enumerate}
\item $\mathring{\Pi}_\mathbb{R} \subseteq T^p_\mathbb{R}$
\item $\varphi^V$ is $\mathring{\Pi}_{R}$-VALID.
\item $\varphi^U = \emptyset \vee (\varphi = \varphi^U \wedge \varphi^V)$
\item $\varphi$ is $\Pi_\mathbb{R}$-UNSAT $\implies$ $\varphi$ is $T^p_\mathbb{R}$-UNSAT
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item Easy from the definition.
\item Easy to see.
\item Easy from the transitions.
\item The proof is done inductively:
\begin{itemize}
\item \sloppy Initial state: $(\bigwedge\limits_{v \in V}v \in (-\infty, +\infty), \varphi, \emptyset, \emptyset, \emptyset)$ and by definition, ${(\bigwedge\limits_{v \in V}v \in (-\infty, +\infty))_\mathbb{R} = T^p_R}$. Then, the invariant trivially holds.
\item Each transition is considered:
\begin{itemize}
\item For rules $\Pi$\_SAT, IA\_SAT the interval constraint $\Pi$ does not changed, so if the properties holds for the former state, it also does for the later one.
\item \sloppy For REFINE transition: \\ Denote ${\Pi' = \Pi \wedge (\neg I_j \vee I_{j1} \vee I_{j2}) \wedge (I_j \vee \neg I_{j1}) \wedge (I_j \vee \neg I_{j2}) \wedge (\neg I_{j1} \vee \neg I_{j2})}$. We will prove that $\varphi$ is $\Pi'_\mathbb{R}$-UNSAT $\implies \varphi$ is $\Pi_\mathbb{R}$-UNSAT. First suppose that $\varphi$ is $\Pi'_\mathbb{R}$-UNSAT. Let
\item for IA\_UNSAT transition, 
\end{itemize}
\end{itemize}
\end{enumerate}
\end{proof}

\begin{theorem}
Let $\varphi$ be the polynomial constraint to be solved. Starting with the state $(\Pi, \varphi, \emptyset, \emptyset, \emptyset)$, if our transitional system terminates and output:
\begin{itemize}
\item SAT then $\varphi$ is $T^p_\mathbb{R}$-SAT.
\item UNSAT then $\varphi$ is $T^p_\mathbb{R}$-UNSAT.
\end{itemize}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item If the system output SAT, there are two possibles transition to SAT:
\begin{itemize}
\item In the case of IA\_VALID, we have $\varphi^V$ is $\mathring{\Pi}_{R}$-VALID (invariant 2) $\implies \varphi^V$ is $\mathring{\Pi}_\mathbb{R}$-SAT $\implies \varphi$ is $\mathring{\Pi}_\mathbb{R}$-SAT (because $\varphi^V = \varphi$ is the condition of this transition). In addition, following invariant 1, we have $\mathring{\Pi}_\mathbb{R} \subseteq T^p_\mathbb{R}$, then $\varphi$ is $T^p_\mathbb{R}$-SAT (Lemma ~\ref{lemma:subtheory-SAT}).
\item \sloppy In the case of TEST\_SAT, $\varphi^U$ is $\mathring{\Pi}_\mathbb{R}$-SAT $\implies \exists M \in \mathring{\Pi}_\mathbb{R} \; \models_M \varphi^V$. Let ${M^c_\mathbb{R} \in \mathring{\Pi}_\mathbb{R}}$ such that $\models_{M^c_\mathbb{R}} \varphi^V$ which implies $(\varphi^V)^{M^c_\mathbb{R}} = 1$. In addition, because $\varphi^V$ is $\mathring{\Pi}_\mathbb{R}$-VALID (invariant 2) and $M^c_\mathbb{R} \in \mathring{\Pi}_\mathbb{R}$, we have $\models_{M^c_\mathbb{R}} \varphi^U$ or ${(\varphi^U)^{M^c_\mathbb{R}} = 1}$. Consider the evaluation of $\varphi$ under the model $M^c_\mathbb{R}$: ${(\varphi)^{M^c_\mathbb{R}} = (\varphi^U \wedge \varphi^V)^{M^c_\mathbb{R}}}$ (invariant 3) $= min((\varphi^U)^{M^c_\mathbb{R}}, (\varphi^V)^{M^c_\mathbb{R}}) = min(1, 1) = 1 \implies \models_{M^c_\mathbb{R}} \varphi \implies \varphi$ is $\mathring{\Pi}_\mathbb{R}$-SAT $\implies \varphi$ is $T^p_\mathbb{R}$-SAT (because of invariant 1 and Lemma ~\ref{lemma:IA-R-OP})
\end{itemize}
\item  If the system output UNSAT, there is only one transition of rule $\Pi$\_UNSAT. Because $\Pi \models_{SAT} \bot$, $\Pi_\mathbb{R}$ is empty (Lemma ?). As a result, $\varphi$ is $\Pi_\mathbb{R}$-UNSAT which implies that $\varphi$ is $T^p_\mathbb{R}$-UNSAT (invariant 4).
\end{enumerate}
\end{proof}

\subsection{Completeness}
\begin{definition} \label{def:OT-complete}
\sloppy
Let $\Pi = \bigwedge\limits_{v \in V} v \in i$ with $i \in \mathbb{I}$, and ${\varphi = \bigwedge\limits_{i=1}^n f_i > 0}$. An over-approximation $T^p_O$ of $T^p_\mathbb{R}$ is complete if for each open set ${O \subset \{(r_1,r_2,\cdots) |  \models_{\theta^\mathbb{I}} \Pi; \theta = \{v_i \mapsto r_i \in \mathbb{R} | v_i  \in V\}\}}$, we have ${\forall c \in O; \; \forall \delta > 0; \; \exists \gamma > 0; \; (\langle c - \gamma, c + \gamma \rangle \in O \text{ and } \models_{\Pi'^p_\mathbb{R}} \bigwedge\limits_{i=1}^n(f_i(c)-\delta < f_i(x) < f_i(c) + \delta)}$ where ${\Pi' = \bigwedge\limits_{v_i \in V} v_i \in \langle c_i - \gamma, c_i + \gamma \rangle}$, and ${c = (c_1, c_2, \cdots)}$
\end{definition}

\begin{lemma} \label{lem:sat-complete}
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is bounded; and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. Denote $S = \{(x_1, x_2, \cdots) | \theta = \{v_i \mapsto x_i | v_i \in V \}; \models_{\theta^I} \Pi \text{ and } \models_{\theta^p_\mathbb{R}}\varphi \}$. If $S \neq \emptyset$ and $\{(v_1, v_2, \cdots) | v_1 \in (l_1, h_1), v_2 \in (l_2, h_2) \cdots \}$ is open, then $S$ contain an open set.
\end{lemma}

\begin{proof}
\sloppy
Because $S \neq \emptyset$, there exist $c = (c_1, c_2, \cdots) \in S$. By definition of $S$, ${\forall j \in \{1, \cdots, n\} f_j(c) > 0}$. Take $\delta = \min\limits_{j=1\cdots n} f_j(c)$, then $\delta > 0$. Because the polynomials are continuous, there exists $\gamma > 0$ such that $\forall v \in \langle c - \gamma, c + \gamma \rangle; \; \bigwedge\limits_{j=1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ which implies ${\forall v \in \langle c - \gamma, c + \gamma \rangle; \; \bigwedge\limits_{j=1}^n f_j(v) > 0}$ (because $\delta = \min\limits_{j=1\cdots n}f_j(c) \le f_j(c)$) for any $j$.
Now consider the open interval $O = \{(x_1, x_2, \cdots) | x_1 \in getIntv(c_1, l_1, h_2, \delta), \cdots \}$ where $getIntv(c, l, h, \delta)$ is defined as following:
\begin{center}
$getIntv(c, l, h, \delta) = $
\end{center}
\end{proof}


\begin{theorem} \label{theorem:SAT-complete}
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is bounded; and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. Denote $S = \{(x_1, x_2, \cdots) | \theta = \{v_i \mapsto x_i | v_i \in V \}; \models_{\theta^I} \Pi \text{ and } \models_{\theta^p_\mathbb{R}}\varphi \}$. If $S \neq \emptyset$ and $\{(v_1, v_2, \cdots) | v_1 \in (l_1, h_1), v_2 \in (l_2, h_2) \cdots \}$ is open, then raSATloop can detect the satisfiability of $\varphi$ with assumption that IA is complete.
\end{theorem}


\begin{proof}
Based on Lemma~\ref{lem:sat-complete}, there exist an open box $(l, h)$ such that $\forall (x_1, x_2, ...) \in (l, h); \; \bigwedge\limits_{j=1}^n f_j > 0 $. Take any $c \in (l, h)$ and take $\delta = \min\limits_{j = 1\cdots n}(f_j(c))$. Because IA is complete by assumption, from Definition~\ref{def:OT-complete} there exists $\gamma > 0$ such that $\langle c - \gamma, c + \gamma \rangle \in (l, h)$ and $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is ${\bigwedge\limits_{v_i \in V}v_i \in \langle c_i - \gamma, c_i + \gamma \rangle}^p_{IA}$-VALID. By taking this $\gamma$ as the threshold in $(\Pi, \varphi, \emptyset, \emptyset, \varepsilon, \bot)$, raSATloop will terminate (Theorem~\ref{theorem:terminating}). Furthermore, $\langle c - \gamma, c + \gamma \rangle \in (l, h) \implies (c + \gamma) - (c - \gamma) < h - l \implies 2\gamma < h - l$. As a consequence, decomposition eventually creates a box of size $\gamma$ inside $(h, l)$ which can be used to conclude the validity of the constraint by IA.
\end{proof}


\begin{theorem} \label{theorem:UNSAT-complete}
\sloppy
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is bounded; and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. Denote $S_j = \{(x_1, x_2, \cdots) | \theta = \{v_i \mapsto x_i | v_i \in V \};\models_{\theta^I} \Pi \text{ and } \models_{\theta^p_\mathbb{R}}f_j \}$. If $\bigcap\limits_{j = 1}^nclosure(S_j) = \emptyset$, then raSATloop can prove the unsatisfiability of $\varphi$ with assumption that IA is complete.
\end{theorem}


\begin{proof}
\sloppy
Let $f(v) = \min\limits_{j = 1}^nf_j(v)$, then $f(v)$ is continuous. Because ${D = \{(x_1, x_2, \cdots) | \theta = \{v_1 \mapsto x_1, v_2 \mapsto x_2, \cdots\}; \models_{\theta^I} \Pi\}}$ is compact, ${\delta = |\max\limits_{v \in D}f(v)}|$ exists. First we will prove that $\delta > 0$. In fact, suppose $\delta = 0 \implies \forall c \in D; \; f(c) = 0 \implies \forall c \in D \forall j \in \{1, \cdots, n\}f_j(c) \ge 0$. This contradicts with the assumption that $\bigcap\limits_{j = 1}^nclosure(S_j) = \emptyset$.

Because IA is complete, by Definition~\ref{def:OT-complete}, for any point $c \in D$, there exists $\gamma > 0$ such that $\langle c - \gamma, c + \gamma \rangle \in D$ and $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is ${\bigwedge\limits_{v_i \in V}v_i \in \langle c_i - \gamma, c_i + \gamma \rangle}^p_{IA}$-VALID. Consider $f_k(c) = \min\limits_{j=1}^nf_j(c)$ then $f_k(c) < 0$ otherwise a contradiction with the assumption that $\bigcap\limits_{j = 1}^nclosure(S_j) = \emptyset$ exists. In addition by definition of $f(v)$ we have $f_k(c) = f(c) \le \max\limits_{v \in D}f(v) \implies f_k(c) + \delta < 0 \implies \bigwedge\limits_{j = 1}^n f_j(v) > 0$ is UNSAT over $\bigwedge\limits_{v_i \in V}v_i \in \langle c_i - \gamma, c_i + \gamma \rangle$. For any point in $D$, we can find a small box so that the constraint is unsatisfiable. If $\varepsilon$ is small enough, the unsatisfiability can be detected by raSATloop.
\end{proof}


\begin{comment}
\section{Over-Approximation Theory Refinement}
\label{sec:soundness}

From now on, We focus on a \emph{polynomial inequality} such that 
$I_i$ and $\psi_j(x_1,\cdots,x_n)$ are an open interval $(a_i,b_i)$ and 
an atomic polynomial inequaltiy (API) $f_j > 0$, respectively. 
We denote $\mathbb{S}(f_j) = \{x \in \Real^n \mid f_j > 0 ~\text{holds}\}$.

For ICP, it is folklore that, for polynomial inequality 
$\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$, 
\begin{itemize}
\item if $\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$ is SAT, 
ICP eventually detects it, and 
\item if $\exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT, 
ICP eventually detects it, 
\end{itemize}
under the assumptions of {\em fair} decomposition and bounded intervals $(a_i,b_i)$. 
We will prepare terminology and briefly review this fact. 

%%%%%%%%%%%%%%%%%%%%%%
\suppress{
\begin{definition} \label{def:poly}
A polynomial inequality is a bounded quantification 
$\exists x_1 \in I_1 \cdots x_n \in I_n. \psi(x_1,\cdots,x_n)$ 
such that 
\begin{itemize}
\item each $I_i$ is an open interval $x_i \in (a_i,b_i)$, and 
\item $\psi(x_1,\cdots,x_n)$ is a conjunction of $f_j > 0$ 
where $f_j$ is a polynomial over $\{x_1, \cdots, x_n\}$. 
\end{itemize}
$f_i > 0$ is called an atomic polynomial inequality (API). 
We denote $\mathbb{S}(F) = \{x \in \Real^n \mid F ~\text{holds}\}$.
\end{definition}

\begin{example} \label{examp:poly_ieq}
$\exists x \in (-1,3)~y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$
is an example of a polynomial inequality with 2 variables and 2 APIs. 
\end{example}
}
%%%%%%%%%%%%%%%%%%%%%%

\begin{definition}
An \emph{open box} of dimension $n$ is a set $(a_1,b_1) \times \cdots \times (a_n,b_n)$ 
where $a_i, b_i \in \Real, a_i \leq b_i$.  
For $\mathfrak{a} = (a_1, \cdots, a_n)$ and $\mathfrak{b} = (b_1, \cdots, b_n)$, 
we denote $(a_1,b_1) \times \cdots \times (a_n,b_n)$ by $(\mathfrak{a}, \mathfrak{b})$. 
\end{definition}

The set of all open boxes is a basis of Euclidean topology on $\Real^n$. 
In $\Real^n$, a set $U$ is compact if, and only if, $U$ is a bounded closed set. 
We denote a closure of a set $U$ by $\overline{U}$. 
%
Since a polynomial is continuous, 
$\mathbb{S}(\bigwedge \limits_{i=1}^m f_i > 0)$ is an open set. 
Note that $\Rat$ is dense in $\Real$, and an SAT instance in reals can be replaced with one in rationals. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\suppress{
\begin{lemma} \label{cor:rattoreal}
For a polynomial inequality
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$, 
If there exists an SAT instance of F in $\Real^n$, there exists also in $\Rat^n$. 
\end{lemma}

\begin{lemma} \label{cor:refinement}
Suppose that $a_j < b_j$ for $1 \leq j \leq n$ and $f_i$'s are polynomials. 
Assume $a_k < c < b_k$ for some $k$. 
Then, 
$\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n). \bigwedge \limits_{i=1}^m f_i > 0$ 
is SAT (resp. UNSAT) if, and only if, 
$\exists x_1 \in (a_1,b_1) \cdots x_k \in (a_k,c) \cdots x_n \in (a_n,b_n). 
 \bigwedge \limits_{i=1}^m f_i > 0 
 \vee 
 \exists x_1 \in (a_1,b_1) \cdots x_k \in (c,b_k) \cdots x_n \in (a_n,b_n)). 
 \bigwedge \limits_{i=1}^m f_i > 0$ 
is SAT (resp. UNSAT). 
\end{lemma}

\begin{pf}
We show for the SAT case. If-part is obvious. For only-if-part, 
since $\mathbb{S}(\bigwedge \limits_{i=1}^m f_i > 0)$ is an open set, 
if $y \in (a_1,b_1) \times \cdots \{c\} \cdots \times (a_n,b_n)$ satisfies 
$\bigwedge \limits_{i=1}^m f_i > 0$, 
there exists $x_1 \in (a_1,b_1) \cdots x_k \in (a_k,c) \cdots x_n \in (a_n,b_n)$
(also $x_1 \in (a_1,b_1) \cdots x_k \in (c,b_k) \cdots x_n \in (a_n,b_n)$) that satisfies
$\bigwedge \limits_{i=1}^m f_i > 0$. 
\end{pf}

Lemma~\ref{cor:rattoreal} says that proving SAT of $F$ in $\Real$ is reduced to 
that in $\Rat$. 
Lemma~\ref{cor:refinement} says that, in the refinement step, we can apply refinement 
$x_k \in (a_k,b_k)$ to $x_k \in (a_k,c) \vee x_k \in (c,b_k)$, 
instead of $x_k \in (a_k,c] \vee x_k \in (c,b_k) $
(i.e., $c$ is ignored). 
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Initially, interval constraints consists of conjunction only. Later, by refinements, it becomes a CNF. 


%\begin{example} \label{examp:poly_ieq}
$\exists x \in (-1,3)~y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$
is an example of a polynomial inequality with 2 variables and 2 APIs. 

For instance, $x \in (-1,3)$ and $y \in (2,4)$ are refined to smaller intervals
such that 
$\exists x \in (-1,1) y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0) \vee 
 \exists x \in (1,3) y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$, 
which results a CNF 
$(x \in (-1,1) \vee x \in (1,3)) \wedge (y \in (2,4)) \wedge (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$.
%(only the CNF formula $(x \in (-1,1) \vee x \in (1,3)) \wedge (y \in (2,4))$ is given to SAT solver).
%\mizuhito{could you fulfill? Direct encoding seems a DNF?}. 
%\end{example}

Note that an interval arithmetic used in ICP is a converging theory. 

\begin{definition} \label{def:completeOT}
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
be a polynomial inequality such that each $I_i$ is bounded. 
An over-approximation theory $O.T$ is {\em converging} 
if, for each $\delta > 0$ and $c = (c_1, \cdots, c_n) \in I_1 \times \cdots \times I_n$, 
there exists $\gamma > 0$ such that 
$\bigwedge \limits_{j=1}^n x_j \in (c_j - \gamma, c_j + \gamma) \models_{O.T} 
 \bigwedge \limits_{i=1}^m (f_i(c) - \delta < f_i(x) < f_i(c) + \delta)$. 
\end{definition}

$O.T$ refinemnet loop is shown in Fig.~\ref{fig:OTrefine}~(a). 
A standard ICP based algorithm of an SMT solver applies it with $O.T$ as a classical interval arithemtic. 
The variation of interval arithemtic will be presented in Section~\ref{sec:approximation}. 
\begin{figure}[ht]
\begin{minipage}[b]{1.0\linewidth}
\centering
\begin{tabular}{c@{\quad}c}
\includegraphics[height=0.6in,width=1.7in]{OTloop.png} & 
\includegraphics[height=0.9in,width=1.7in]{rasatloop.png} \\   
\mbox{(a) $O.T$ refinement loop} & \mbox{{\bf raSAT} loop} \\
\end{tabular}
\end{minipage} 
\caption{Rfinement loops} 
\label{fig:OTrefine} 
\end{figure}


\begin{definition} 
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
for $I_i = (a_i,b_i)$.
A refinement strategy is {\em fair}, if, for each $c_j \in (a_j,b_j)$ and $\gamma > 0$, 
a decomposition of $I_i$ for each $i$ eventually occurs in $(c_j - \gamma, c_j + \gamma)$ 
(as long as neither SAT nor UNSAT is detected). 
\end{definition}

\begin{theorem} \label{theorem:RelComp}
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
for $I_i = (a_i,b_i)$.
Assume that an over-approximation theory $O.T$ is converging, 
each $(a_i,b_i)$ is bounded, and a refinement strategy is fair. 
Then, 
\begin{itemize}
\item if $\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$ is SAT, 
$O.T$ refinemnet loop eventually detects it, and
\item if $\exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT, 
$O.T$ refinement loop eventually detects it.  
\end{itemize}
\end{theorem}


\begin{proof} 
The former is proved by the fact that, if $F$ is SAT, there exists a non-empty neiborhood (open box) 
in $\cap~\mathbb{S}(f_j)$. 
If the box decomposition strategy is fair, the refinemnet will eventually find such an open box. 

For the latter, assume that 
$\overline{F} = \exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT. 
Thus, $\cap~\overline{\mathbb{S}(f_i)} = \emptyset$. 
Let $\delta_{j,k} = min \{|f_j(\bar{x}) - f_k(\bar{x})| \mid \bar{x} \in I_1 \times \cdots \times I_n\}$. 
Since $f_i$'s are continuous and $\overline{I_i}$'s are compact, $\delta_{j,k}$ is well defined,
and $\delta_{j.k} > 0$ for some $j,k$. 
Let $\delta = \frac{min \{ \delta_{j,k} \}}{2}$. 
Since $O.T$ is converging, there exists $\gamma > 0$ for $\delta > 0$ 
satisfying Definition~\ref{def:completeOT}, and fair decomposition eventually finds open boxes
such that $\mathbb{S}(f_j)$ and $\mathbb{S}(f_k)$ are separated. 
%\qed
\end{proof}

Limitations for detecting UNSAT occur on \emph{kissing} and \emph{convergent} cases. 
Fig.~\ref{fig:limit} left shows a kissing case 
$x^2 + y^2 < 2^2 \wedge (x-4)^2 + (y-3)^2 < 3^2$ such that 
$\overline{\mathbb{S}(- x^2 - y^2 + 2^2)} \cap \overline{\mathbb{S}(- (x-4)^2 - (y-3)^2 + 3^2)} 
= \{(x,y) \mid (1.6, 1.2)\}$. 
Thus, there are no coverings to separate them. 
%$x^2 + y^2 < 2^2$ and $(x-4)^2 + (y-3)^2 < 3^2$. 
%
Fig. \ref{fig:limit} right shows a convergent case 
$y > x + \frac{1}{x} \wedge y < x \wedge x > 0$, which is equivalent to 
$xy > x^2 + x \wedge y < x \wedge x > 0$. 
%The open box is $(0,\infty) \times (0,\infty)$ and 
There are no finite coverings to separate them. 
%$y > x + \frac{1}{x}$ and $y < x$ for $x > 0$. 

\begin{figure}[ht]
%\begin{minipage}[b]{1.0\linewidth}
\centering
\begin{tabular}{cc}
\includegraphics[height=1.65in,width=1.7in]{kissing.eps} &
\includegraphics[height=1.65in,width=1.7in]{convergence.eps}
\end{tabular}
\caption{Limitations for proving UNSAT} 
\label{fig:limit} 
%\end{minipage}
\end{figure} 
\end{comment}