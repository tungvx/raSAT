\chapter{Over-Approximation and Under-Approximation}\label{chap:OT-UT}
\section{Approximation Theory}
\begin{comment}
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_j \psi_j(x_1,\cdots,x_n)$, 
%\exists x_1 \ldots x_n. (\underbrace{\bigwedge \limits_i x_i \in I_i}_{I}) \wedge 
%                       (\underbrace{\bigwedge \limits_j \psi_j(x_1,\cdots,x_n)}_{P})
where $\psi_j(x_1,\cdots,x_n)$ is an atomic formula. 
%
$F$ is equivalnet to 
$\exists x_1 \ldots x_n. (\bigwedge \limits_i x_i \in I_i) \wedge (\bigwedge \limits_j \psi_j(x_1,\cdots,x_n))$, 
and we call $\bigwedge \limits_i x_i \in I_i$ {\em interval constraints}, and 
we refer $\bigwedge \limits_j \psi_j(x_1,\cdots,x_n)$ by $\psi(x_1,\cdots,x_n)$. 
Initially, interval constraints have a form of the conjunction $\bigwedge \limits_i x_i \in I_i$, 
and later by refinement, $x_i \in I_i$ is decomposed into a clause $\bigvee_j x_i \in I_{i_j}$, 
which makes a CNF. 

As an SMT (SAT modulo theory) problem, 
boolean variables are assigned to each $x_i \in I_{i_j}$, 
and truth assignments is produced by a SAT solver, 
which are proved or disproved by a background theory $T$ whether it satisfies $\psi(x_1,\cdots,x_n)$. 

As notational convention, $m$ (the lower case) denotes 
a variable assignments on $x_i$'s, and 
$M$ (the upper case) denotes a truth assignment on $x_i \in I_{i_j}$'s. 
We write $m \in M$ when an instance $m = \{ x_i \leftarrow c_i \}$ satisfies 
all $c_i \in I_{i_j}$ that are assigned true by $M$. 

We assume {\em very lazy theory learning}~\cite{dpll}, and 
a backend theory $T$ is applied only for a full truth assignment $M$. 
%We regard $M$ as a conjunction $\bigwedge \limits_i x_i \in I_{i_j}$. 
\begin{itemize}
\item If an instance $m$ satisfies $\psi(x_1,\cdots,x_n)$, we denote $m \models_T \psi(x_1,\cdots,x_n)$. 
\item If each instance $m$ with $m \in M$ satisfies $\psi(x_1,\cdots,x_n)$, 
we denote $M \models_T \psi(x_1,\cdots,x_n)$. 
\end{itemize}
\end{comment}

\begin{comment}
\begin{definition} \label{def:app}
Let $F = \exists x_1 \in I_1 \cdots x_n \in I_n. \psi(x_1,\cdots,x_n)$. 
For a truth assignment on $M$, $F$ is 
\begin{itemize}
\item $T$-valid if $M \models_T \psi(x_1,\cdots,$ $x_n)$, 
\item $T$-satisfiable ($T$-SAT) if $m \models_T \psi(x_1,\cdots,x_n)$ 
for some $m \in M$, and 
\item $T$-unsatisfiable ($T$-UNSAT) if $M \models_T \neg \psi(x_1,\cdots,x_n)$. 
\end{itemize}
If $T$ is clear from the context, we simply say valid, satisfiable, and unsatisfiable. 
\end{definition}
\end{comment}

%%%%%%%%%%%%%
\suppress{
Then, Fig. \ref{fig:T_result} illustrates Definition~\ref{def:app}. 
\begin{figure} [ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
  \includegraphics[height=1.8in,width=1.9in]{T_result.eps}
\caption{Results of a target constraint $F$ in a theory $T$}
\label{fig:T_result}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
   \includegraphics[height=2.2in,width=2.3in]{frame_app.eps}
\caption{{\bf raSAT} loop}
\label{fig:frame}
\end{minipage}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{definition} \label{def:ApproxTheory}
Let $T, T'$ be $\Sigma$-theories and $\varphi$ be any $\Sigma$-formula. 
\begin{itemize}
\item[$\bullet$] $T'$ is an {\em over-approximation theory} of $T$ 
iff $T'$-UNSAT of $\varphi$ implies $T$-UNSAT of $\varphi$.
\item[$\bullet$] $T'$ is an {\em under-approximation theory} of $T$
iff $T'$-SAT of $\varphi$ implies $T$-SAT of $\varphi$. 
\end{itemize}
\end{definition}

\begin{theorem} \label{theorem:OT_VALID}
If $T_O$ be an over-approximation theory of $T$, then for any $\Sigma$-formula $\varphi$: $\varphi$ is $T_O$-VALID implies $\varphi$ is $T$-VALID.
\end{theorem}

\begin{proof}
$\varphi$ is $T_O$-VALID $\implies$ $\neg\varphi$ is $T_O$-UNSAT (Lemma \ref{lemma:theory-valid-unsat}) $\implies \neg\varphi$ is $T$-UNSAT (Definition \ref{def:ApproxTheory}) $\implies \varphi$ is T-VALID (Lemma \ref{lemma:theory-valid-unsat})
\end{proof}


\section{Interval Arithmetic as an Over-Approximation Theory}\label{sec:IA}
\subsection{Real Intervals}
We adopt the definition of real intervals from \cite{Hickey:2001:IAP:502102.502106}:
\begin{definition}\cite{Hickey:2001:IAP:502102.502106}
Let $a$ and $b$ be reals such that $a \le b$.
\begin{center}
\begin{tabular}{ r c l }
  $\langle a, b \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | a \le x \le b\}$ \\
  $\langle -\infty, b \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | x \le b\}$ \\
  $\langle a, +\infty \rangle$ & $\overset{def}{=}$ & $\{x \in \mathbb{R} | a \le x\}$ \\  
  $\langle -\infty, +\infty \rangle$ & $\overset{def}{=}$ & $\mathbb{R}$ \\  
\end{tabular}
\end{center}
\end{definition}
The \emph{intervals} in this definition can be summarized by $\langle a, b \rangle$ where $a, b \in \mathbb{R} \cup \{-\infty, +\infty\}$ and $a \le b$ with the assumption that $\forall c \in \mathbb{R}-\infty < c < \infty$. Furthermore, \citet{Hickey:2001:IAP:502102.502106} also defined arithmetic operations for $\mathbb{R} \cup \{-\infty, +\infty\}$ which is summarized in Table~\ref{tab:arithOp}.

\begin{table} 
\begin{tabular}{c||*{5}{c|}}
$x + y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$-\infty$&$-\infty$&$-\infty$&$-\infty$&$\bot$\\\hline
$NR$ &&NR&NR&$\mathbb{R}$&$+\infty$\\\hline
$0$&&&0&PR&$+\infty$\\\hline
$PR$ &&&&PR&$+\infty$\\\hline
$+\infty$ &&&&&$+\infty$\\\hline
\end{tabular}
\quad
\begin{tabular}{c||*{5}{c|}}
$x - y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$\bot$&$+\infty$&$+\infty$&$+\infty$&$+\infty$\\\hline
$NR$ &$-\infty$&$\mathbb{R}$&PR&PR&$+\infty$\\\hline
$0$&$-\infty$&NR&0&PR&$+\infty$\\\hline
$PR$ &$-\infty$&NR&NR&$\mathbb{R}$&$+\infty$\\\hline
$+\infty$ &$-\infty$&$-\infty$&$-\infty$&$-\infty$&$\bot$\\\hline
\end{tabular}
\newline
\vspace*{1 cm}
\newline
\begin{center}
\begin{tabular}{c||*{5}{c|}}
$x * y$
&$-\infty$&NR&0
&PR&$+\infty$\\\hline
$-\infty$ &$+\infty$&$+\infty$&$\bot$&$-\infty$&$-\infty$\\\hline
$NR$ &&PR&0&NR&$-\infty$\\\hline
$0$&&&0&0&$\bot$\\\hline
$PR$ &&&&PR&$+\infty$\\\hline
$+\infty$ &&&&&$+\infty$\\\hline
\end{tabular}
\end{center}
\caption{Arithmetics Operations for $\mathbb{R} \cup \{-\infty, +\infty\}$}
\label{tab:arithOp}
\end{table}

\begin{definition} \label{def:real_intervals}
The set of all \emph{real intervals} $\mathbb{I}$ is defined as: \[\mathbb{I} = \{\langle a, b \rangle \mid a, b \in \mathbb{R} \cup \{-\infty, +\infty\} \text{ and } a \le b \}\].
\end{definition}

\subsection{Interval Arithmetic as an Over-Approximation Theory} \label{sec:Gen-IA}
\sloppy
A model $M^p_{IA} = (\mathbb{I}, I^p_{IA})$ over intervals for polynomial constraints consists a set of all real intervals $\mathbb{I}$ and a map $I^p_{IA}$ that satisfies the following conditions.
\begin{enumerate}
\item $I^p_{IA}(Real) = \mathbb{I}$
\item For all $p \in P^p$, $I^p_{IA}(p)$ is a function from $\mathbb{I}\times \mathbb{I}$ to $\{0, 1\}$ where \[I^p_{IA}(p)(i_1, i_2) = i_1 \; p_{IA} \; i_2\] The definition of $ p_{IA}$ is as follow:
\begin{center}
\begin{tabular} {r c l}
$\langle l_1, h_1\rangle  \succ_{IA} \langle l_2,  h_2\rangle$  &=& $\left\{ 
  \begin{array}{c l}
    1 & \quad \text{if } l_1 > h_2\\
    0 & \quad \text{if } h_1 \le l_2 \\
  \end{array} \right.$ \\
  
$\langle l_1, h_1\rangle  \prec_{IA} \langle l_2,  h_2\rangle$ & = & $\left\{ 
  \begin{array}{c l}
    1 & \quad \text{if } h_1 < l_2\\
    0 & \quad \text{if } l_1 \ge h_2 \\
  \end{array} \right.$\\
  
$i_1 \succeq_{IA} i_2$ &=& $1 - (i_1 \prec_{IA} i_2)$\\

$i_1 \preceq_{IA} i_2$ &=& $1 - (i_1 \succ_{IA} i_2)$ \\
$i_1 \approx_{IA} i_2 $ &=& $ min (i_1 \succeq_{IA} i_2, i_1 \preceq_{IA} i_2)$\\
$i_1 \not\approx_{IA} i_2 $ &=& $ 1 - (i_1 \approx_{IA} i_2)$
\end{tabular}
\end{center}

\item For all $f \in F^p \setminus \{\mathbf{1}\}$, $I^p_{IA}(f)$ is a function from $\mathbb{I} \times \mathbb{I} \mapsto \mathbb{I}$ such that \[I^p_{IA}(f)(i_1, i_2)= i_1 \; f_{IA} \; i_2\] where $f_{IA}$ satisfies the following properties:
\begin{itemize}
\item[$\bullet$] $i_1 \oplus_{IA} i_2 \supseteq \{r_1 + r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\item[$\bullet$] $i_1 \ominus_{IA} i_2 \supseteq \{r_1 - r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\item[$\bullet$] $i_1 \otimes_{IA} i_2 \supseteq \{r_1 * r_2| r_1 \in i_1 \text{ and } r_2 \in i_2\}$.
\end{itemize}
\item $I^p_{IA}(\mathbf{1}) = \langle 1,1\rangle $
\item For all $v \in V$; $I^p_{IA} \in U^p_{IA}$
\end{enumerate}
Theory $T^p_{IA} = \{M^p_{IA}| M^p_{IA} \text{ is a model over intervals}\}$. Each model differs to another by the mapping from variables to intervals. As a consequence, one assignment from variables to intervals can be used to describe an model. In addition, an assignment $\{v \mapsto i \in \mathbb{I} | v \in V\}$ and an interval constraint $\bigwedge\limits_{v \in V} v \in i$ are equivalent in terms of the set of assignments from variables to real numbers. So by abusing notation, for a constraint of the form $\Pi = \bigwedge\limits_{v \in V} v \in i$, we denote $\Pi^p_{IA}$ as a model of interval arithmetics for polynomial constraints. By definition, $\{\Pi^p_{IA}\}$ represents a sub-theory of $T^p_{IA}$.

\begin{lemma} \label{lemma:IA-R-OP}
Let $M^p_{IA} = (\mathbb{I}, I^p_{IA})$ be a model over intervals, ${i_1, i_2 \in \mathbb{I}}$, ${r_1 \in i_2, r_2 \in i_2}$, ${p \in P^p}$, we have ${i_1 \; p_{IA} \; i_2 = 0}$ implies not $(r_1 \; p_\mathbb{R} \; r_2)$
\end{lemma}


\begin{example}
We have $\langle 1, 3 \rangle \succ_{IA} \langle 5, 8 \rangle = 0$ by the definition of $\prec_{IA}$. Take $2 \in \langle 1, 3 \rangle$ and $6 \in \langle 5, 8 \rangle$. Following Lemma~\ref{lemma:IA-R-OP}, we have $not \; (2 \prec_\mathbb{R} 6)$ holds or $not \; (2 < 6)$ holds (because $\prec_\mathbb{R} \; = \; <$) which is obviously true.
\end{example}

\begin{proof}
Let $i_1 = \langle l_1, h_1\rangle $ and $i_2 = \langle l_2, h_2\rangle $ where $l_1 \le h_1$ and $l_2 \le h_2$. We have: 
\begin{itemize}
\item[$\bullet$] $r_1 \in i_1$ implies $l_1 \le r_1 \le h_1$, and
\item[$\bullet$] $r_2 \in i_2$ implies $l_2 \le r_2 \le h_2$.
\end{itemize}
Suppose  that $i_1 \; p_{IA} \; i_2 = 0 $, we need to show $not \; (r_1 \; p_\mathbb{R} \; r_2)$ by considering all the possible cases of $p$:
\begin{enumerate}
\item If $p$ is $\succ$, we have $\langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle  = 0  \implies h_1 \le l_2 \implies r_1 \le r_2$ (because $r_1 \le h_1$ and $l_2 \le r_2$) $\implies not \; (r_1 > r2) \implies not \; (r_1 \succ_\mathbb{R} r_2)$.
\item If $p$ is $\prec$, we have $\langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle  = 0  \implies l_1 \ge h_2 \implies r_1 \ge r_2$ (because $r_1 \ge l_1$ and $r_2 \le h_2$) $\implies not \; (r_1 < r_2) \implies not \; (r_1 \prec_\mathbb{R} r_2)$.
\item If $p$ is $\succeq$, we have $\langle l_1, h_1\rangle  \succeq_{IA} \langle l_2, h_2\rangle  = 0  \implies {1 -  (\langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle ) = 0}  \implies \langle l_1, h_1\rangle  \prec_{IA} \langle l_2, h_2\rangle  = 1 \implies h_1 < l_2 \implies r_1 < r_2$ (because $r_1 \le h_1$ and $r_2 \ge l_2$) $\implies not \; (r_1 \ge r_2) \implies not \; (r_1 \succeq_\mathbb{R} r_2)$.
\item If $p$ is $\preceq$, we have $\langle l_1, h_1\rangle  \preceq_{IA} \langle l_2, h_2\rangle  = 0  \implies {1 - (\langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle ) = 0}  \implies \langle l_1, h_1\rangle  \succ_{IA} \langle l_2, h_2\rangle  = 1 \implies l_1 > h	_2 \implies r_1 > r_2$ (because $r_1 \ge l_1$ and $r_2 \le h_2$) $\implies not \; (r_1 \le r_2) \implies not \; (r_1 \preceq_\mathbb{R} r_2)$.
\item If $p$ is $\approx$, we have $i_1 \approx_{IA} i_2 = 0  \implies min(i_1 \succeq_{IA} i_2 , i_1 \preceq_{IA} i_2) = 0  \implies {i_1 \succeq_{IA} i_2 = 0}  \text{ or } i_1 \preceq_{IA} i_2 = 0  \implies r_1 < r_2 \text{ or } r_1 > r_2$ (as the third and fourth case of this proof) $\implies not \; (r_1 = r_2) \implies not \; (r_1 \approx_\mathbb{R} r_2)$.
\item \sloppy If $p$ is $\not\approx$, we have $i_1 \not\approx_{IA} i_2 = 0  \implies 1 - (i_1 \approx_{IA} i_2) = 0  \implies {min(i_1 \succeq_{IA} i_2, i_1 \preceq_{IA} i_2) = 1} \implies i_1 \succeq_{IA} i_2 = 1$ and $i_1 \preceq_{IA} i_2 = 1   \implies 1 - (i_1 \prec_{IA} i_2) = 1 \text{ and } 1 - (i_1 \succ_{IA} i_2) = 1  \implies {i_1 \prec_{IA} i_2 = 0  \text{ and } i_1 \succ_{IA} i_2 = 0}  \implies {r_1 \ge r_2} \text{ and } {r_1 \le r_2}$ (as the first and second case of this proof) $\implies r_1 = r_2 \implies not \; (r_1 \not= r_2) \implies not \; (r_1 \not\approx_\mathbb{R} r_2)$.
\end{enumerate}
\end{proof}

\begin{lemma} \label{lemma:IA-OT}
Let $\Pi = \bigwedge\limits_{v \in V}v \in i$ with $i \in \mathbb{I}$, $g$ is a polynomial ($\Sigma^p$-term). For every model over real numbers $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$, we have $g^{M^p_\mathbb{R}} \in g^{\Pi^p_{IA}}$.
\end{lemma}
The intention of this lemma is that for given a box of variables' intervals and a polynomial, interval arithmetic will, essentially, output an interval that contains all the possible values of the polynomial with respect to any point inside the box.
\begin{proof}
Let $M^p_\mathbb{R} = (\mathbb{R}, I^p_\mathbb{R}) \in \Pi^p_\mathbb{R}$. As mentioned in Section~\ref{sec:Gen-IA}, $\Pi$ can also be referred as a map from variables to intervals, i.e. $\{v \mapsto i \mid v \in V\}$. Proof is done by induction on structure of polynomial $f$.
\begin{enumerate}
\item \textbf{Base case}
\begin{itemize}
\item[$\bullet$] If $g = v \in V$, we have 
\begin{center}
\begin{tabular} {r c l}
$v^{M^p_\mathbb{R}}$ &=& $I^p_\mathbb{R}(v) \in \Pi(v) \text{ because  } M^p_\mathbb{R} \in \Pi^p_\mathbb{R}, \text{ and }$\\ $v^{\Pi^p_{IA}}$ &=& $\Pi(v)$\\
\end{tabular}
\end{center}
Then, $v^{M^p_\mathbb{R}} \in v^{\Pi^p_{IA}}$.

\item[$\bullet$] If $g = \mathbf{1}$, then $\mathbf{1}^{M^p_\mathbb{R}} = 1 \in \langle 1, 1\rangle  = \mathbf{1}^{\Pi^p_{IA}}$
\end{itemize}

\item \textbf{Induction case:} $g = f(g_1, g_2)$ for some $f \in F^p \setminus \{\mathbf{1}\}$.

We have

\begin{center}
\begin{tabular} {r c l}
$f^{M^p_\mathbb{R}}(g_1, g_2)$ &=& $g_1^{M^p_\mathbb{R}} \; f_\mathbb{R} \; g_2^{M^p_\mathbb{R}}$ \\
$f^{\Pi^p_{IA}}(g_1, g_2)$ &=& $g_1^{\Pi^p_{IA}} \; f_{IA} \; g_2^{\Pi^p_{IA}}$
\end{tabular}
\end{center}

By induction hypothesis, we have $g_1^{M^p_\mathbb{R}} \in g_1^{\Pi^p_{IA}}$ and $g_2^{M^p_\mathbb{R}} \in g_2^{\Pi^p_{IA}}$ which due to the properties of $f_{IA}$ implies $g_1^{M^p_\mathbb{R}} \; f_\mathbb{R} \; g_1^{M^p_\mathbb{R}} \in g_2^{\Pi^p_{IA}} \; f_{IA} \; g_2^{\Pi^p_{IA}}$, or $g^{M^p_\mathbb{R}} \in g^{\Pi^p_{IA}}$ 
\end{enumerate}
\end{proof}


\begin{theorem} \label{theorem:IA-OverAprox}
Let $\Pi = \bigwedge\limits_{v \in V}v \in i$ with $i \in \mathbb{I}$, then $\{\Pi^p_{IA}\}$ is an over-approximation of $\Pi^p_\mathbb{R}$.
\end{theorem}

\begin{proof}
Given an polynomial constraint $\varphi$ and suppose that $\varphi$ is $\{\Pi^p_{IA}\}$-UNSAT. We will prove that $\varphi$ is $\Pi^p_\mathbb{R}$-UNSAT by induction on structure of $\varphi$.

\begin{enumerate}
\item \textbf{Base case:} \sloppy $\varphi^p = p(g_1, g_2)$ for some $p \in P^p$. 

We prove the lemma for the base case by contradiction. Suppose $\varphi$ is not $\Pi^p_\mathbb{R}$-UNSAT, that means it is either  $\Pi^p_\mathbb{R}$-SAT or  $\Pi^p_\mathbb{R}$-VALID. In either case, there exist at least a model $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$ such that $\models_{M^p_\mathbb{R}} \varphi \iff \varphi^{M^p_\mathbb{R}}= 1$. We have
\begin{equation} \label{eq:3.1}
\varphi^{M^p_\mathbb{R}}= 1 \implies g_1^{M^p_\mathbb{R}} \; p_\mathbb{R} \; g_2^{M^p_\mathbb{R}}
\end{equation}

On the other hand, \[\varphi\text{ is }\{\Pi^p_{IA}\}\text{-UNSAT} \implies \varphi^{\Pi^p_{IA}} = 0  \implies g_1^{\Pi^p_{IA}} \; p_{IA} \; g_2^{\Pi^p_{IA}} = 0 \] 

In addition, because $g_1^{M^p_\mathbb{R}} \in g_1^{\Pi^p_{IA}}$ and $g_2^{M^p_\mathbb{R}} \in g_2^{\Pi^p_{IA}}$ (Lemma ~\ref{lemma:IA-OT}), we have 

\begin{equation} \label{eq:3.2}
{g_1^{\Pi^p_{IA}} \; p_{IA} \; g_2^{\Pi^p_{IA}} = 0}  \implies \text{not }(g_1^{M^p_\mathbb{R}} \; p_\mathbb{R} \; g_2^{M^p_\mathbb{R}}) \text{(Lemma ~\ref{lemma:IA-R-OP})}
\end{equation}

Contradiction is raised between (\ref{eq:3.1}) and (\ref{eq:3.2}).
As the result, $\varphi$ must be $\Pi^p_\mathbb{R}$-UNSAT.

\item \textbf{Induction case:} $\varphi = \varphi_1 \wedge \varphi_2$.

We have $\varphi$ is  $\{\Pi^p_{IA}\}$-UNSAT $\implies \not\models_{\Pi^p_{IA}}(\varphi_1 \wedge \varphi_2) \implies ({\varphi_1 \wedge \varphi_2)^{\Pi^p_{IA}} = 0}  \implies \max(\varphi_1^{\Pi^p_{IA}}, \varphi_2^{\Pi^p_{IA}}) = 0  \implies \varphi_1^{\Pi^p_{IA}} = 0 $ and ${\varphi_2^{\Pi^p_{IA}} = 0}$. 

Thus, by induction hypothesis, $\varphi_1$ and $\varphi_2$ are $\Pi^p_\mathbb{R}$-UNSAT $\implies$ for all $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}, \; \not\models_{M^p_{IA}} \varphi_1$ and for all $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}, \; \not\models_{M^p_{IA}} \varphi_2 \implies$ for all $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}, \; \not\models_{M^p_{IA}} (\varphi_1 \wedge \varphi_2) \implies \varphi_1 \wedge \varphi_2$ is $\Pi^p_\mathbb{R}$-UNSAT.
\end{enumerate}
\end{proof}

\section{Testing as an Under-Approximation Theory}
\begin{definition}
Let $T \subseteq T^p_\mathbb{R}$ be a sub-theory of real numbers. Any sub-theory $T_T$ of $T$, i.e. $T_T \subseteq T$ is call a theory of testing with respect to $T$.
\end{definition}

\begin{theorem}
If $T_T$ is a theory of testing w.r.t $T$, $T_T$ is an under-approximation of $T$.
\end{theorem}

\begin{proof}
Let $\varphi$ be a polynomial constraint and suppose it is $T_T$-SAT. We need to prove $\varphi$ is $T$-SAT. 

We have $\varphi$ is $T_T$-SAT $\implies $ there exists $M \in T_T$ such that $\models_{M} \varphi \implies $ there exists $M \in T$ such that $\models_{M} \varphi$ {(because $T_T \subseteq T$)} $\implies \varphi$ is $T$-SAT.
\end{proof}

Given the interval constraint $\Pi = \bigwedge\limits_{v_i \in V} v \in \langle l_i, h_i \rangle$, we have $\Pi^p_\mathbb{R}$ is a sub-theory of $T^p_\mathbb{R}$. We randomly select a number of models from $\Pi^p_\mathbb{R}$ (by randomly picking values for variables) to form the testing theory $(\Pi^p_\mathbb{R})_T$ of $\Pi^p_\mathbb{R}$.

\begin{example}
Let $\Pi = x \in \langle 1, 5 \rangle \wedge y \in \langle -5, 10 \rangle$ be an interval constraint. If we pick two values for $x$ (e.g. $\{0, 2\}$) and one value for $y$ (e.g. $\{-3\}$), we will have two assignments from real numbers to variables:
\begin{align*}
\theta_1 &= \{x \mapsto 0, y \mapsto -3\} \text{, and} \\
\theta_1 &= \{x \mapsto 2, y \mapsto -3\}
\end{align*}
Thus, the testing theory $(\Pi^p_\mathbb{R})_T$ of $\Pi^p_\mathbb{R}$ is

\[(\Pi^p_\mathbb{R})_T = \{(\theta_1)^p_\mathbb{R}, (\theta_2)^p_\mathbb{R}\}\]
\end{example}

\section{raSAT Loop} 
Our algorithm \textbf{raSAT} loop is described using a transition system. Each state of the search procedure is represented by $(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)$ where 
\begin{itemize}
\item[$\bullet$] $\Pi$ is a CNF interval constraint.
\item[$\bullet$] $\varphi$ represents the polynomial constraint.
\item[$\bullet$] $\mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ with $\langle l_i, h_i \rangle \in \mathbb{I}$. We use $\emptyset$ to denote the empty conjunction.
\item[$\bullet$] $\varphi^V$ consists of conjunction of inequalities that are VALID under over-approximation. We use $\emptyset$ to denote the empty conjunction.
\item[$\bullet$] $\varphi^U$ is the set of inequalities which are UNKNOWN under over-approximation. We use $\emptyset$ to denote the empty conjunction.
\item[$\bullet$] $\varepsilon$ indicates the threshold to stop decomposing intervals.
\item[$\bullet$] $\tau$ is a flag to mark whether the threshold of intervals has been reached. It can be one of two values $\bot$ and $\top$. In the initial state, $\tau$ is always $\bot$.
\end{itemize}
The transition rules are described in Table ~\ref{tab:transition-rules}. Figure ~\ref{fig:smt-design} illustrates the transition system. Given one box (product of variables' intervals), e.g. $(x, y) \in \langle 1, 5 \rangle \times \langle -3, 8 \rangle$, IA and Testing attempt to show the satisfiability/unsatisfiability of the constraint. If neither does, the interval of some variable is decomposed in to smaller intervals, e.g. $\langle 1, 5 \rangle$ of x is decomposed into $\langle 1, 2 \rangle$ and $\langle 2, 5 \rangle$; creating two boxes, e.g. $\langle 1, 2 \rangle \times \langle -3, 8 \rangle$ and $\langle 2, 5 \rangle \times \langle -3, 8 \rangle$. Each of these box will be examined in next iterations. We use a SAT solver which implements DPLL procedure to 
handle the combinations(boxes) of variables intervals by considering each interval, e.g $x \in \langle 1, 5 \rangle$, as a propositional atom. The boxes is represented by interval constraint $\Pi$ and $\mathring{\Pi}$ represents the output of DPLL procedure on $\Pi$. We use threshold $\epsilon$ to prevent some interval to be decomposed deeply. When a box has the size smaller that $\epsilon$, it is pruned by being removed from the considering boxes represented by $\Pi$. The transition rules can be understood as following.
\begin{itemize}
\item[$\bullet$]\textbf{$\pmb\Pi$\_UNSAT}: The DPLL procedure fails to find an assignment that satisfy $\Pi$ (in terms of propositional logic), then there are no more boxes that possibly make the constraint satisfiable. Because no intervals were pruned by threshold ($\tau = \bot$), the given constraint is unsatisfiable with respect to the initial box.
\item[$\bullet$]\textbf{$\pmb\Pi$\_UNKNOWN}: The DPLL procedure fails and some intervals were pruned by threshold ($\tau = \top$), we can conclude neither SAT nor UNSAT.
\item[$\bullet$]\textbf{$\pmb\Pi$\_SAT}: DPLL procedure outputs one assignment representing a box which is stored in $\mathring{\Pi}$. We call this box is \emph{the current box}. The box is sent to Interval Arithmetic modules to check against the constraint.
\item[$\bullet$]\textbf{IA\_UNSAT}: If IA can prove that the constraint is unsatisfiable in the current box, the box will be removed from the considering boxes simply by adding $\neg\mathring{\Pi}$ into $\Pi$.
\item[$\bullet$]\textbf{IA\_SAT}: If IA does not disprove the constraint with respect to the current box, the inequalities in the given constraint is divided into two set: 
\begin{itemize}
\item $\varphi^V$ consisting of inequalities that are proved to be VALID in the current box by IA and
\item $\varphi^U$ (possibly empty) consisting of remaining inequalities. 
\end{itemize}
\item[$\bullet$]\textbf{IA\_VALID}: If IA showed that all the inequalities are VALID in the current box ($\varphi^U = \emptyset$), we can conclude the satisfiability of the constraint. 
\item[$\bullet$]\textbf{TEST\_SAT}: Inequalities $\varphi^U \not= \emptyset$ that can not be verified by IA are passed to the Testing module. If some instances in the current box of variables are found that make $\varphi^U$ satisfiable, we can conclude that $\varphi$ is satisfiable because $\varphi^V$ is satisfiable for all instances in the current box (proved by IA).
\item[$\bullet$]\textbf{THRESHOLD}: Neither IA nor Testing concludes the constraint and the current box has the size smaller than threshold $\epsilon$, the box will be also removed from the considering boxes and $\tau$ is set to $\top$ to mark this pruning.
\item[$\bullet$]\textbf{REFINE}: Neither IA nor Testing concludes the constraint and the some interval of the current box has the size larger than threshold $\epsilon$, decomposition is implemented on that interval.
\end{itemize}
\begin{table*}[t]
  \centering
  \begin{tabular}{ll}
  \hline\\
  \large 
  $\frac{\emptyset \parallel \Pi \Longrightarrow^! FailState}{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \bot) \to UNSAT}$ \tiny $\Pi$\_UNSAT \\\\
  \large 
  $\frac{\emptyset \parallel \Pi \Longrightarrow^! FailState}{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \top) \to UNKNOWN}$ \tiny $\Pi$\_UNKNOWN \\\\
  \large 
  $\frac{\emptyset \parallel \Pi \Longrightarrow^! \mathring{\Pi} }{(\Pi, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi, \varphi, \mathring{\Pi}, \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny $\Pi$\_SAT\\\\
  \large
  $\frac{\mathring{\Pi} \not= \emptyset \quad   \varphi^V \wedge \varphi^U = \varphi \quad \varphi^V \text{ is }  \{\mathring{\Pi}^p_{IA}\}\text{-VALID}}{(\Pi, \varphi, \mathring{\Pi}, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)}$ \tiny IA\_SAT \\\\  
  \large 
  $\frac{\varphi^V = \varphi}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to SAT}$ \tiny IA\_VALID \\\\
  \large 
  $\frac{\mathring{\Pi} \not= \emptyset \quad \varphi^U \not= \emptyset \quad \varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-SAT}}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to SAT}$ \tiny TEST\_SAT \\\\
  \large     
  $\frac{\varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-UNSAT} \quad \mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle \quad \forall i (h_i - l_i < \varepsilon)}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to (\Pi \wedge \neg \mathring{\Pi}, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \top)}$ \tiny THRESHOLD \\\\
  \normalsize 
  $\frac{\varphi^U \text{ is }  (\mathring{\Pi}^p_\mathbb{R})_T\text{-UNSAT} \quad \mathring{\Pi} = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle \quad \exists j(h_j - l_j > \varepsilon) \quad l_j < d \in \mathbb{R} < h_j \quad I_j = v_j \in \langle l_j, h_j \rangle \quad I_{j1} = v_j \in \langle l_j, d\rangle \quad I_{j2} = v_j \in \langle d, h_j \rangle}{(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau) \to (\Pi \wedge (\neg I_j \vee I_{j1} \vee I_{j2}) \wedge (I_j \vee \neg I_{j1}) \wedge (I_j \vee \neg I_{j2}) \wedge (\neg I_{j1} \vee \neg I_{j2}), \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny REFINE \\\\
  \large 
  $\frac{\mathring{\Pi} \not= \emptyset \quad \varphi \text{ is }  \{\mathring{\Pi}^p_{IA}\}\text{-UNSAT}}{(\Pi, \varphi, \mathring{\Pi}, \emptyset, \emptyset, \varepsilon, \tau) \to (\Pi \wedge \neg\mathring{\Pi}, \varphi, \emptyset, \emptyset, \emptyset, \varepsilon, \tau)}$ \tiny IA\_UNSAT \\\\
  \hline\\
  \end{tabular}
  \caption{Transition rules}\label{tab:transition-rules}
\end{table*}

\begin{figure}[ht]
%\begin{minipage}[b]{1.0\linewidth}
\centering
\includegraphics[width=\textwidth]{smt-design.png} 
\caption{\textbf{raSAT} design} 
\label{fig:smt-design} 
%\end{minipage}
\end{figure}

\begin{theorem} \label{theorem:terminating}
Starting with state ${(\Pi, \varphi, \emptyset, \emptyset, \varepsilon, \bot)}$, if $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ and ${\langle l_1, h_1 \rangle \times \langle l_2, h_2 \rangle \times \cdots}$ is bounded, raSATloop terminates.
\end{theorem}

\begin{proof}
In the worst case, all the interval will be decomposed into smallest boxes with size of $\varepsilon$ whose number are bounded to $\frac{h_1 - l_1}{\varepsilon}*\frac{h_2 - l_2}{\varepsilon}*\cdots$ (the number of variables in one polynomial constraint is also bounded). As a result, raSATloop terminates after checking all of these boxes.
\end{proof}

\begin{example}
In Theorem~\ref{theorem:terminating}, if $\Pi= x \in \langle 1, 5 \rangle \wedge y \in \langle -3, 8 \rangle$ and $\epsilon = 0.1$, then decomposition will create maximally \[\frac{5 - 1}{0.1}*\frac{8 - (-3)}{0.1} = 150\] boxes.
\end{example}

\section{Soundness - Completeness}
\subsection{Soundness}
\begin{theorem}
Let $(\Pi_0, \varphi_0, \mathring{\Pi}_0, \varphi^V_0, \varphi^U_0, \varepsilon, \bot)$ be the starting state and $(\Pi, \varphi, \mathring{\Pi}, \varphi^V, \varphi^U, \varepsilon, \tau)$ be any state of our system, then the following properties are invariants:
\begin{enumerate}
\item $\mathring{\Pi}^p_\mathbb{R} \subseteq T^p_\mathbb{R}$
\item $\varphi^V$ is $\mathring{\Pi}^p_{R}$-VALID.
\item $\varphi^U = \emptyset \vee (\varphi = \varphi^U \wedge \varphi^V)$
\item $\varphi$ is $\Pi^p_\mathbb{R}$-UNSAT and $\tau = \bot$ implies that $\varphi$ is $(\Pi_0)^p_\mathbb{R}$-UNSAT
\end{enumerate}
\end{theorem}

\begin{proof}   
\begin{enumerate}
\item Easy from the definition.
\item Easy from the transitions and the fact that $\{\mathring{\Pi}^p_{IA}\}$ is an over-approximation of $\mathring{\Pi}^p_\mathbb{R}$ (Theorem~\ref{theorem:IA-OverAprox}).
\item Easy from the transitions.
\item The proof is done inductively on transitions of the system:
\begin{itemize}
\item[$\bullet$] \sloppy \textbf{Initial state:} It is obvious because $\Pi = \Pi_0$.
\item[$\bullet$] \textbf{Transitions}:
\begin{itemize}
\item \textbf{$\pmb\Pi$\_SAT} and \textbf{IA\_SAT}: The interval constraint $\Pi$ does not changed, so if the properties holds for the former state, it also does for the later one.
\item \sloppy \textbf{REFINE}: \\ Denote ${\Pi' = \Pi \wedge \Pi''}$ where: \[\Pi'' = (\neg I_j \vee I_{j1} \vee I_{j2}) \wedge (I_j \vee \neg I_{j1}) \wedge (I_j \vee \neg I_{j2}) \wedge (\neg I_{j1} \vee \neg I_{j2})\] We will prove $(\Pi')^p_\mathbb{R} = \Pi^p_\mathbb{R}$ by showing $(\Pi')^p_\mathbb{R} \in \Pi^p_\mathbb{R}$ and $(\Pi')^p_\mathbb{R} \ni \Pi^p_\mathbb{R}$.

$\pmb{(\Pi')^p_\mathbb{R} \in \Pi^p_\mathbb{R}}$: Let $M^p_\mathbb{R}=(\mathbb{R}, I^p_\mathbb{R})$ be any model in $(\Pi')^p_\mathbb{R}$ and ${\theta = \{v \mapsto I^p_\mathbb{R}(v) \mid v \in V\}}$. By definition, we have $\theta^p_\mathbb{R}=M^p_\mathbb{R}$. Because $M^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}$, it is the case that $\models_{\theta^I_\mathbb{R}} \Pi'$, which implies
\begin{tabular} {l l}
$(\Pi')^{\theta^I_\mathbb{R}} = 1$ &$\implies$ $(\Pi \wedge \Pi'' )^{\theta^I_\mathbb{R}} = 1 \implies \min((\Pi)^{\theta^I_\mathbb{R}}, (\Pi'')^{\theta^I_\mathbb{R}}) = 1$ \\
&$\implies (\Pi)^{\theta^I_\mathbb{R}} \text{ and } (\Pi'')^{\theta^I_\mathbb{R}} \implies \models_{\theta^I_\mathbb{R}} \Pi \implies \theta^p_\mathbb{R} \in \Pi^p_\mathbb{R}$
\end{tabular}

or $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$. As the result, $(\Pi')^p_\mathbb{R} \in \Pi^p_\mathbb{R}$.

$\pmb{\Pi^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}}$: Let $M^p_\mathbb{R}=(\mathbb{R}, I^p_\mathbb{R})$ be any model in $\Pi^p_\mathbb{R}$ and ${\theta = \{v \mapsto I^p_\mathbb{R}(v) \mid v \in V\}}$. By definition, we have $\theta^p_\mathbb{R}=M^p_\mathbb{R}$. Because $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$, it is the case that $\models_{\theta^I_\mathbb{R}} \Pi$. There are two possible cases: $\models_{\theta^I_\mathbb{R}} I_j$ or $\not\models_{\theta^I_\mathbb{R}} I_j$. In the first case, by the construction of $I_{j1}$ and $I_{j2}$ we can imply that $\models_{\theta^I_\mathbb{R}} I_{j1}$ or $\models_{\theta^I_\mathbb{R}} I_{j2}$. These imply $\models_{\theta^I_\mathbb{R}} \Pi''$ and thus $\models_{\theta^I_\mathbb{R}} \Pi'$ or $M^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}$. In the second case, i.e. $\not\models_{\theta^I_\mathbb{R}} I_j$, again by the construction of $I_{j1}$ and $I_{j2}$, $\not\models_{\theta^I_\mathbb{R}} I_j$ implies $\not\models_{\theta^I_\mathbb{R}} I_{j1}$ and $\not\models_{\theta^I_\mathbb{R}} I_{j2}$. These imply that $\not\models_{\theta^I_\mathbb{R}} \Pi''$ (by some simple calculation we can prove that $(\Pi'')^{\theta^p_\mathbb{R}} = 1$). As a result, $\models_{\theta^I_\mathbb{R}} \Pi'$ or $M^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}$. 

In either case, we have $M^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}$ for any $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$. Then, $\Pi^p_\mathbb{R} \in (\Pi')^p_\mathbb{R}$.

\item \textbf{IA\_UNSAT}: suppose $\varphi$ is $(\Pi \wedge \neg\mathring{\Pi})^p_\mathbb{R}$-UNSAT. We need to prove that $\varphi$ is $\Pi^p_\mathbb{R}$-UNSAT. Let $M^p_\mathbb{R} = (\mathbb{R}, I^p_\mathbb{R})$ be any model in $\Pi^p_\mathbb{R}$ and ${\theta = \{v \mapsto I^p_\mathbb{R}(v) \mid v \in V\}}$. The later is the assignment from real numbers to variables that are included in the former and by definition $M^p_\mathbb{R} = \theta^p_\mathbb{R}$. Because $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$, be definition of $\Pi^p_\mathbb{R}$ we have $\models_{\theta^I_\mathbb{R}}\Pi$.
There are two possible cases: either $\models_{\theta^I_\mathbb{R}} \mathring{\Pi}$ or $\not\models_{\theta^I_\mathbb{R}} \mathring{\Pi}$.

If $\models_{\theta^I_\mathbb{R}} \mathring{\Pi}$, by definition $\theta^p_\mathbb{R} \in \mathring{\Pi}^p_\mathbb{R}$. In addition because $\varphi$ is $\{\mathring{\Pi}^p_IA\}$-UNSAT, $\varphi$ is $\mathring{\Pi}^p_\mathbb{R}$-UNSAT (derived from Theorem~\ref{theorem:IA-OverAprox}). As a result, $\not\models_{\theta^p_R}\varphi$ or $\not\models_{M^p_R}\varphi$.

If $\not\models_{\theta^I_\mathbb{R}} \mathring{\Pi}$, then by Lemma~\ref{lemma:model-sat-unsat} we have $\models_{\theta^I_\mathbb{R}} \neg\mathring{\Pi}$ which implies $\models_{\theta^I_\mathbb{R}} \Pi \wedge \neg\mathring{\Pi}$ (because $\models_{\theta^I_\mathbb{R}}\Pi$). By definition this implies $\theta^p_\mathbb{R} \in (\Pi \wedge \neg\mathring{\Pi})^p_\mathbb{R}$ or $M^p_\mathbb{R} \in (\Pi \wedge \neg\mathring{\Pi})^p_\mathbb{R}$. In addition because $\varphi$ is $(\Pi \wedge \neg\mathring{\Pi})^p_\mathbb{R}$-UNSAT, we can imply $\not\models_{M^p_\mathbb{R}}\varphi$

In any cases, we can imply that $\not\models_{M^p_\mathbb{R}}\varphi$ for any $M^p_\mathbb{R} \in \Pi^p_\mathbb{R}$. In other words, $\varphi$ is $\Pi^p_\mathbb{R}$-UNSAT.
\end{itemize}
\end{itemize}
\end{enumerate}
\end{proof}

\begin{theorem}
Let $\varphi$ be the polynomial constraint to be solved. Starting with the state $(\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle -\infty, +\infty \rangle, \varphi, \emptyset, \emptyset, \emptyset, \epsilon, \bot)$, if our transitional system terminates and output:
\begin{itemize}
\item[$\bullet$] SAT then $\varphi$ is $T^p_\mathbb{R}$-SAT.
\item[$\bullet$] UNSAT then $\varphi$ is $T^p_\mathbb{R}$-UNSAT.
\end{itemize}
\end{theorem}

\begin{proof} Because the starting state is $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle -\infty, +\infty \rangle$, by definition we have $\Pi^p_\mathbb{R} = T^p_\mathbb{R}$.
\begin{itemize}
\item[$\bullet$] If the system output SAT, there are two possibles transition to SAT:
\begin{itemize}
\item In the case of IA\_VALID, we have $\varphi^V$ is $\mathring{\Pi}_{R}^p$-VALID (invariant 2) $\implies \varphi^V$ is $\mathring{\Pi}^p_\mathbb{R}$-SAT $\implies \varphi$ is $\mathring{\Pi}^p_\mathbb{R}$-SAT (because $\varphi^V = \varphi$ is the condition of this transition). In addition, following invariant 1, we have $\mathring{\Pi}^p_\mathbb{R} \subseteq T^p_\mathbb{R}$, then $\varphi$ is $T^p_\mathbb{R}$-SAT (Lemma~\ref{lemma:subtheory-SAT}).
\item \sloppy In the case of TEST\_SAT, $\varphi^U$ is $\mathring{\Pi}^p_\mathbb{R}$-SAT $\implies$ there exist $M^p_\mathbb{R} \in \mathring{\Pi}^p_\mathbb{R}$ such that $\models_{M^p_\mathbb{R}} \varphi^V \implies (\varphi^V)^{M^c_\mathbb{R}} = 1$. In addition, because $\varphi^V$ is $\mathring{\Pi}^p_\mathbb{R}$-VALID (invariant 2) and $M^p_\mathbb{R} \in \mathring{\Pi}_\mathbb{R}$, we have $\models_{M^p_\mathbb{R}} \varphi^U$ or ${(\varphi^U)^{M^p_\mathbb{R}} = 1}$. Consider the evaluation of $\varphi$ under the model $M^p_\mathbb{R}$: ${(\varphi)^{M^p_\mathbb{R}} = (\varphi^U \wedge \varphi^V)^{M^p_\mathbb{R}}}$ (invariant 3) $= min((\varphi^U)^{M^p_\mathbb{R}}, (\varphi^V)^{M^p_\mathbb{R}}) = min(1, 1) = 1 \implies \models_{M^p_\mathbb{R}} \varphi \implies \varphi$ is $\mathring{\Pi}^p_\mathbb{R}$-SAT $\implies \varphi$ is $T^p_\mathbb{R}$-SAT (because of invariant~1 and Lemma~\ref{lemma:IA-R-OP})
\end{itemize}
\item[$\bullet$]  If the system output UNSAT, there is only one transition of rule $\Pi$\_UNSAT. Because $\emptyset \parallel \Pi \Longrightarrow^! FailState$, $\Pi$ is unsatisfiable in the sense of propositional logic, and thus it cannot be satisfiable in terms of first order logic. As the result, by definition $\Pi^p_\mathbb{R}$ is empty which implies that $\varphi$ is $\Pi^p_\mathbb{R}$-UNSAT. By invariant 4, $\varphi$ is $T^p_\mathbb{R}$-UNSAT.
\end{itemize}
\end{proof}

\subsection{Completeness}
\begin{definition} \label{def:OT-complete}
\sloppy
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$, and ${\varphi = \bigwedge\limits_{i=1}^n f_i > 0}$. An theory $T$ is complete with respect to the theory real numbers over polynomial constraint $T^p_\mathbb{R}$ if for each ${O \subset \langle l_1, h_1 \rangle \times \langle l_2, h_2 \rangle \times \cdots}$, ${c = (c_1, c_2, \cdots) \in O}$, and $\delta > 0$, there exists $\gamma > 0$, $T' \subset T$, such that:
\begin{itemize}
\item[$\bullet$] $\langle c_1 - \gamma, c_1 + \gamma \rangle \times \langle c_2 - \gamma, c_2 + \gamma \rangle \times \cdots \subset O$,
\item[$\bullet$]$\bigwedge\limits_{i=1}^n(f_i(c)-\delta < f_i(x)) \wedge (f_i(x) < f_i(c) + \delta)$ is $T'$-VALID, and
\item[$\bullet$] $T'$ is an over-approximation of $(\Pi')^p_\mathbb{R}$ where ${\Pi' = \bigwedge\limits_{v_i \in V} v_i \in \langle c_i - \gamma, c_i + \gamma \rangle}$.
\end{itemize} 
\end{definition}

\begin{lemma} \label{lem:sat-complete}
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is open, and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. Denote 
\begin{itemize}
\item [$\bullet$] $S_\varphi = \{(r_1, r_2, \cdots) \mid \theta = \{v_i \mapsto r_i \mid v_i \in V \} \text{ and } \models_{\theta^p_\mathbb{R}}\varphi \}$ be the set of points that satisfy the constraint $\varphi$, and
\item [$\bullet$] $S = (\langle l_1, h_1 \rangle \times \langle l_1, h_1 \rangle \times \cdots) \cap S_\varphi$ be the set of points that
\begin{itemize}
\item  are inside the box represented by $\Pi$.
\item satisfy the constraint $\varphi$.
\end{itemize}

\end{itemize}
If $S \neq \emptyset$, then $S$ contain an open set.
\end{lemma}

\begin{proof}
\sloppy
Because $S \neq \emptyset$, there exist $c = (c_1, c_2, \cdots) \in S$. By definition of $S$, for all ${j \in \{1, \cdots, n\}, \, f_j(c) > 0}$. Take $\delta = \min\limits_{j=1\cdots n} f_j(c)$, then $\delta > 0$. Because the polynomials are continuous, there exists $\gamma > 0$ such that for all $v \in \langle c - \gamma, {c + \gamma \rangle, \; \bigwedge\limits_{j=1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta}$ which implies for all ${v \in \langle c - \gamma, c + \gamma \rangle, \; \bigwedge\limits_{j=1}^n f_j(v) > 0}$ (because $\delta = \min\limits_{j=1\cdots n}f_j(c) \le f_j(c)$ for any $j$).
Now consider the open interval \[O = (\max(l_1, c_1 -\gamma), \min(h_1, c_1 + \gamma) \times (\max(l_2, c_2 -\gamma), \min(h_2, c_2 + \gamma) \times \cdots\]
It is easy to see that $O \subset \langle c - \gamma, c + \gamma \rangle \subset S_\varphi$ and ${O \subset \langle l_1, h_1 \rangle \times \langle l_1, h_1 \rangle \times \cdots}$ that implies $O \in S$. In addition because $\langle l_i, h_i \rangle$ is open for each $i=1,2,\cdots$, $O$ is open by its construction.
\end{proof}

\begin{theorem} \label{theorem:SAT-complete}
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is open, and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. \begin{itemize}
\item [$\bullet$] $S_\varphi = \{(r_1, r_2, \cdots) \mid \theta = \{v_i \mapsto r_i \mid v_i \in V \} \text{ and } \models_{\theta^p_\mathbb{R}}\varphi \}$ be the set of points that satisfy the constraint $\varphi$, and
\item [$\bullet$] $S = (\langle l_1, h_1 \rangle \times \langle l_1, h_1 \rangle \times \cdots) \cap S_\varphi$ be the set of points that are inside the box represented by $\Pi$ and also satisfy the constraint $\varphi$.
\end{itemize}


If $S \neq \emptyset$, $(l_1, h_1) \times (l_2, h_2) \times \cdots$ is bounded, and the threshold $\epsilon$ is small enough; then raSATloop can detect the satisfiability of $\varphi$ with assumption that the theory of interval arithmetic $T^p_{IA}$ is complete.
\end{theorem}


\begin{proof}
Based on Lemma~\ref{lem:sat-complete}, there exist an open box $(l, h) \in S$ such that for all $(r_1, r_2, ...) \in (l, h)$, $\bigwedge\limits_{j=1}^n f_j > 0 $. Take any $c \in (l, h)$ and take $\delta = \min\limits_{j = 1\cdots n}(f_j(c))$. Because IA is complete by assumption, from Definition~\ref{def:OT-complete} there exists $\gamma > 0$ and $T \subset T^p_{IA}$ such that
\begin{itemize}
\item[$\bullet$] ${\langle c - \gamma, c + \gamma \rangle \in (l, h)}$,
\item[$\bullet$] $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is $T$-VALID, and
\item [$\bullet$] $T$ is an over-approximation of $(\Pi')^p_\mathbb{R}$ where $\Pi' = \bigwedge\limits_{v_i \in V}v_i \in \langle c_i - \gamma, c_i + \gamma \rangle$.
\end{itemize}
From above second and third conditions, IA can be used to prove that $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is $(\Pi')^p_\mathbb{R}$-VALID (Theorem~\ref{theorem:OT_VALID}) which implies that ${\bigwedge\limits_{j = 1}^n 0 < f_j(v)}$ is $(\Pi')^p_\mathbb{R}$-VALID (because ${\delta = \min\limits_{j = 1\cdots n}(f_j(c)) \implies f_j(c) \ge \delta}$ for all $j = 1, 2, \cdots, n$) or $\varphi$ is $(\Pi')^p_\mathbb{R}$-VALID $\implies$ $\varphi$ is $(\Pi')^p_\mathbb{R}$-SAT $\implies$ $\varphi$ is $T^p_\mathbb{R}$-SAT.

By taking $\gamma$ as the threshold in $(\Pi, \varphi, \emptyset, \emptyset, \gamma, \bot)$, raSATloop will terminate (Theorem~\ref{theorem:terminating}). Furthermore, $\langle c - \gamma, c + \gamma \rangle \in (l, h) \implies (c + \gamma) - (c - \gamma) < h - l \implies 2\gamma < h - l$. As a consequence, decomposition eventually creates a box of size $\gamma$ inside $(h, l)$ which can be used to conclude the satisfiability of the constraint by IA.
\end{proof}

Figure~\ref{fig:complete-sat} illustrates a simple case for this theorem where we have two inequalities and the initial box is represented by $\Pi = x \in \langle a, b \rangle \wedge y \in \langle c, d \rangle$. Here $a < b$ and $c < d$ make the box open. This box intersects with set of points that satisfy both inequalities. As a consequence, decomposition will create a box (the blue one) that can be used by IA to prove the satisfiability of two inequalities.

\begin{figure}[ht]
\centering
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{complete-sat.png} 
\caption{Example of SAT completeness}
\label{fig:complete-sat}
\end{subfigure}
\begin{subfigure}[b]{0.4\textwidth}
\includegraphics[width=\textwidth]{complete-unsat.png} 
\caption{Example of UNSAT completeness}
\label{fig:complete-unsat}
\end{subfigure}
\caption{Examples on complete cases of \textbf{raSAT}} 
\label{fig:complete-ex}
\end{figure}

\begin{theorem} \label{theorem:UNSAT-complete}
\sloppy
Let $\Pi = \bigwedge\limits_{v_i \in V} v_i \in \langle l_i, h_i \rangle$ where $\langle l_i, h_i \rangle \in \mathbb{I}$ is open, and ${\varphi = \bigwedge\limits_{j = 1}^n f_j > 0}$. Denote $S = \{(r_1, r_2, \cdots) \mid \theta = \{v_i \mapsto r_i \mid v_i \in V \}, \models_{\theta^I} \Pi \text{ and } \models_{\theta^p_\mathbb{R}}\bigwedge\limits_{j = 1}^n f_j \ge 0 \}$ be the set of all points which are inside the box represented by $\Pi$ and also satisfy $\bigwedge\limits_{j = 1}^n f_j \ge 0$. If $S = \emptyset$, $(l_1, h_1) \times (l_2, h_2) \times \cdots$ is bounded, and the threshold $\epsilon$ is small enough; then raSATloop can prove the unsatisfiability of $\varphi$ with assumption that the theory of Interval Arithmetic $T^p_{IA}$ is complete.
\end{theorem}


\begin{proof}
\sloppy
Let $f(v) = \min\limits_{j = 1}^nf_j(v)$, then $f(v)$ is continuous. Because $D = \langle l_1, h_1 \rangle \times \langle l_2, h_2 \rangle \times \cdots$ is compact, ${\delta = |\max\limits_{v \in D}f(v)}|$ exists. 

First we will prove that $\delta > 0$. In fact, suppose $\delta = 0 \implies |\max\limits_{v \in D}f(v)| = 0 \implies$ for all $c \in D, \; f(c) = 0 \implies$ for all $c \in D, \; \min\limits_{j = 1}^nf_j(c) = 0 \implies$ for all $c \in D$, for all $j \in \{1, \cdots, n\}, f_j(c) \ge 0$. This contradicts with the assumption that $S = \emptyset$.

Because $T^p_{IA}$ is complete, by Definition~\ref{def:OT-complete}, for any point $c \in D$, there exists $\gamma > 0$ and $T \subset T^p_{IA}$ such that 
\begin{itemize}
\item[$\bullet$] $\langle c - \gamma, c + \gamma \rangle \in D$,
\item[$\bullet$] $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is $T$-VALID, and
\item[$\bullet$] $T$ is an over-approximation of $(\Pi')^p_\mathbb{R}$ where $\Pi' = \bigwedge\limits_{v_i \in V}v_i \in \langle c_i - \gamma, c_i + \gamma \rangle$.
\end{itemize} 
From above second and third conditions, IA can be used to prove $\bigwedge\limits_{j = 1}^n f_j(c) - \delta < f_j(v) < f_j(c) + \delta$ is $(\Pi')^p_\mathbb{R}$-VALID (Theorem~\ref{theorem:OT_VALID}).

Let $f_k(c) = \min\limits_{j=1}^nf_j(c)$ for $k \in \{1, 2, \cdots, n\}$ then $f_k(c) < 0$ otherwise a contradiction with the assumption that $S = \emptyset$ exists. In addition, by definition of $f(v)$ we have $f_k(c) = f(c)$ which implies $|f_k(c)| \le |\max\limits_{v \in D}f(v)| \implies f_k(c) + \delta \le 0$. Moreover, IA can prove that $f_k(v) < f_k(c) + \delta$ is $(\Pi')^p_\mathbb{R}$-VALID. We have $f_k(v) < f_k(c) + \delta$ is $(\Pi')^p_\mathbb{R}$-VALID $\implies$ $f_k(v) < 0$ is $(\Pi')^p_\mathbb{R}$-VALID $\implies$ $\neg(f_k(v) < 0) = f_k(v) \ge 0$ is $(\Pi')^p_\mathbb{R}$-UNSAT (Lemma~\ref{lemma:theory-valid-unsat}) $\implies$ $f_k(v) > 0$ is $(\Pi')^p_\mathbb{R}$-UNSAT  $\implies \bigwedge\limits_{j = 1}^n f_j(v) > 0$ is $(\Pi')^p_\mathbb{R}$-UNSAT. 

In conclusion, for any point in $D$, we can find a small box containing that point in which the constraint can be proved to be unsatisfiable by IA. As a result, if $\varepsilon$ is small enough, \textbf{raSAT} loop will terminate (Theorem~\ref{theorem:terminating}) and proves the unsatisfiability of the constraint after checking all the small decomposed boxes.
\end{proof}

Figure~\ref{fig:complete-unsat} illustrates a simple example for this theorem where we have two inequalities and the initial box is represented by $\Pi = x \in \langle a, b \rangle \wedge y \in \langle c, d \rangle$. Here $a < b$ and $c < d$ make the box open. The constraint is unsatisfiable inside the box and decomposition will eventually separate two satisfiable areas of two inequalities.

The limitation of UNSAT detection comes from the case of kissing situation. Figure~\ref{fig:kissing} presents an example of this with the constraint \[x^2 + y^2 < 4 \wedge (x-4)^2 + (y-3)^2 < 9\]
which is UNSAT but Interval Arithmetic can not uses boxes to separate the satisfiable areas around the touching points of two inequalities. The condition $S = \emptyset$ in the above Theorem avoids such a kissing situation.  

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{UNSAT-touching.png} 
\caption{Kissing situation}
\label{fig:kissing}
\end{figure}

Note that is Theorem~\ref{theorem:SAT-complete}~and~\ref{theorem:SAT-complete} requires that the threshold $\epsilon$ is small enough. Although computing this enough small $\epsilon$ is not easy, \textbf{raSAT} achieves this by incremental deepening (Chapter~\ref{chap:strate}) strategy in which the value of threshold is made to be smaller if \textbf{raSAT} fails to conclude the constraint.
\begin{comment}
\section{Over-Approximation Theory Refinement}
\label{sec:soundness}

From now on, We focus on a \emph{polynomial inequality} such that 
$I_i$ and $\psi_j(x_1,\cdots,x_n)$ are an open interval $(a_i,b_i)$ and 
an atomic polynomial inequaltiy (API) $f_j > 0$, respectively. 
We denote $\mathbb{S}(f_j) = \{x \in \Real^n \mid f_j > 0 ~\text{holds}\}$.

For ICP, it is folklore that, for polynomial inequality 
$\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$, 
\begin{itemize}
\item if $\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$ is SAT, 
ICP eventually detects it, and 
\item if $\exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT, 
ICP eventually detects it, 
\end{itemize}
under the assumptions of {\em fair} decomposition and bounded intervals $(a_i,b_i)$. 
We will prepare terminology and briefly review this fact. 

%%%%%%%%%%%%%%%%%%%%%%
\suppress{
\begin{definition} \label{def:poly}
A polynomial inequality is a bounded quantification 
$\exists x_1 \in I_1 \cdots x_n \in I_n. \psi(x_1,\cdots,x_n)$ 
such that 
\begin{itemize}
\item each $I_i$ is an open interval $x_i \in (a_i,b_i)$, and 
\item $\psi(x_1,\cdots,x_n)$ is a conjunction of $f_j > 0$ 
where $f_j$ is a polynomial over $\{x_1, \cdots, x_n\}$. 
\end{itemize}
$f_i > 0$ is called an atomic polynomial inequality (API). 
We denote $\mathbb{S}(F) = \{x \in \Real^n \mid F ~\text{holds}\}$.
\end{definition}

\begin{example} \label{examp:poly_ieq}
$\exists x \in (-1,3)~y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$
is an example of a polynomial inequality with 2 variables and 2 APIs. 
\end{example}
}
%%%%%%%%%%%%%%%%%%%%%%

\begin{definition}
An \emph{open box} of dimension $n$ is a set $(a_1,b_1) \times \cdots \times (a_n,b_n)$ 
where $a_i, b_i \in \Real, a_i \leq b_i$.  
For $\mathfrak{a} = (a_1, \cdots, a_n)$ and $\mathfrak{b} = (b_1, \cdots, b_n)$, 
we denote $(a_1,b_1) \times \cdots \times (a_n,b_n)$ by $(\mathfrak{a}, \mathfrak{b})$. 
\end{definition}

The set of all open boxes is a basis of Euclidean topology on $\Real^n$. 
In $\Real^n$, a set $U$ is compact if, and only if, $U$ is a bounded closed set. 
We denote a closure of a set $U$ by $\overline{U}$. 
%
Since a polynomial is continuous, 
$\mathbb{S}(\bigwedge \limits_{i=1}^m f_i > 0)$ is an open set. 
Note that $\Rat$ is dense in $\Real$, and an SAT instance in reals can be replaced with one in rationals. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\suppress{
\begin{lemma} \label{cor:rattoreal}
For a polynomial inequality
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$, 
If there exists an SAT instance of F in $\Real^n$, there exists also in $\Rat^n$. 
\end{lemma}

\begin{lemma} \label{cor:refinement}
Suppose that $a_j < b_j$ for $1 \leq j \leq n$ and $f_i$'s are polynomials. 
Assume $a_k < c < b_k$ for some $k$. 
Then, 
$\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n). \bigwedge \limits_{i=1}^m f_i > 0$ 
is SAT (resp. UNSAT) if, and only if, 
$\exists x_1 \in (a_1,b_1) \cdots x_k \in (a_k,c) \cdots x_n \in (a_n,b_n). 
 \bigwedge \limits_{i=1}^m f_i > 0 
 \vee 
 \exists x_1 \in (a_1,b_1) \cdots x_k \in (c,b_k) \cdots x_n \in (a_n,b_n)). 
 \bigwedge \limits_{i=1}^m f_i > 0$ 
is SAT (resp. UNSAT). 
\end{lemma}

\begin{pf}
We show for the SAT case. If-part is obvious. For only-if-part, 
since $\mathbb{S}(\bigwedge \limits_{i=1}^m f_i > 0)$ is an open set, 
if $y \in (a_1,b_1) \times \cdots \{c\} \cdots \times (a_n,b_n)$ satisfies 
$\bigwedge \limits_{i=1}^m f_i > 0$, 
there exists $x_1 \in (a_1,b_1) \cdots x_k \in (a_k,c) \cdots x_n \in (a_n,b_n)$
(also $x_1 \in (a_1,b_1) \cdots x_k \in (c,b_k) \cdots x_n \in (a_n,b_n)$) that satisfies
$\bigwedge \limits_{i=1}^m f_i > 0$. 
\end{pf}

Lemma~\ref{cor:rattoreal} says that proving SAT of $F$ in $\Real$ is reduced to 
that in $\Rat$. 
Lemma~\ref{cor:refinement} says that, in the refinement step, we can apply refinement 
$x_k \in (a_k,b_k)$ to $x_k \in (a_k,c) \vee x_k \in (c,b_k)$, 
instead of $x_k \in (a_k,c] \vee x_k \in (c,b_k) $
(i.e., $c$ is ignored). 
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Initially, interval constraints consists of conjunction only. Later, by refinements, it becomes a CNF. 


%\begin{example} \label{examp:poly_ieq}
$\exists x \in (-1,3)~y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$
is an example of a polynomial inequality with 2 variables and 2 APIs. 

For instance, $x \in (-1,3)$ and $y \in (2,4)$ are refined to smaller intervals
such that 
$\exists x \in (-1,1) y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0) \vee 
 \exists x \in (1,3) y \in (2,4) . (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$, 
which results a CNF 
$(x \in (-1,1) \vee x \in (1,3)) \wedge (y \in (2,4)) \wedge (x^3y - y^4 > 0) \wedge (y^3 -xy >0)$.
%(only the CNF formula $(x \in (-1,1) \vee x \in (1,3)) \wedge (y \in (2,4))$ is given to SAT solver).
%\mizuhito{could you fulfill? Direct encoding seems a DNF?}. 
%\end{example}

Note that an interval arithmetic used in ICP is a converging theory. 

\begin{definition} \label{def:completeOT}
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
be a polynomial inequality such that each $I_i$ is bounded. 
An over-approximation theory $O.T$ is {\em converging} 
if, for each $\delta > 0$ and $c = (c_1, \cdots, c_n) \in I_1 \times \cdots \times I_n$, 
there exists $\gamma > 0$ such that 
$\bigwedge \limits_{j=1}^n x_j \in (c_j - \gamma, c_j + \gamma) \models_{O.T} 
 \bigwedge \limits_{i=1}^m (f_i(c) - \delta < f_i(x) < f_i(c) + \delta)$. 
\end{definition}

$O.T$ refinemnet loop is shown in Fig.~\ref{fig:OTrefine}~(a). 
A standard ICP based algorithm of an SMT solver applies it with $O.T$ as a classical interval arithemtic. 
The variation of interval arithemtic will be presented in Section~\ref{sec:approximation}. 
\begin{figure}[ht]
\begin{minipage}[b]{1.0\linewidth}
\centering
\begin{tabular}{c@{\quad}c}
\includegraphics[height=0.6in,width=1.7in]{OTloop.png} & 
\includegraphics[height=0.9in,width=1.7in]{rasatloop.png} \\   
\mbox{(a) $O.T$ refinement loop} & \mbox{{\bf raSAT} loop} \\
\end{tabular}
\end{minipage} 
\caption{Rfinement loops} 
\label{fig:OTrefine} 
\end{figure}


\begin{definition} 
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
for $I_i = (a_i,b_i)$.
A refinement strategy is {\em fair}, if, for each $c_j \in (a_j,b_j)$ and $\gamma > 0$, 
a decomposition of $I_i$ for each $i$ eventually occurs in $(c_j - \gamma, c_j + \gamma)$ 
(as long as neither SAT nor UNSAT is detected). 
\end{definition}

\begin{theorem} \label{theorem:RelComp}
Let
$F = \exists x_1 \in I_1 \cdots x_n \in I_n. \bigwedge \limits_{j=1}^m f_j > 0$
for $I_i = (a_i,b_i)$.
Assume that an over-approximation theory $O.T$ is converging, 
each $(a_i,b_i)$ is bounded, and a refinement strategy is fair. 
Then, 
\begin{itemize}
\item if $\exists x_1 \in (a_1,b_1) \cdots x_n \in (a_n,b_n) . \wedge_{i} f_i > 0$ is SAT, 
$O.T$ refinemnet loop eventually detects it, and
\item if $\exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT, 
$O.T$ refinement loop eventually detects it.  
\end{itemize}
\end{theorem}


\begin{proof} 
The former is proved by the fact that, if $F$ is SAT, there exists a non-empty neiborhood (open box) 
in $\cap~\mathbb{S}(f_j)$. 
If the box decomposition strategy is fair, the refinemnet will eventually find such an open box. 

For the latter, assume that 
$\overline{F} = \exists x_1 \in [a_1,b_1] \cdots x_n \in [a_n,b_n] . \wedge_{i} f_i \geq 0$ is UNSAT. 
Thus, $\cap~\overline{\mathbb{S}(f_i)} = \emptyset$. 
Let $\delta_{j,k} = min \{|f_j(\bar{x}) - f_k(\bar{x})| \mid \bar{x} \in I_1 \times \cdots \times I_n\}$. 
Since $f_i$'s are continuous and $\overline{I_i}$'s are compact, $\delta_{j,k}$ is well defined,
and $\delta_{j.k} > 0$ for some $j,k$. 
Let $\delta = \frac{min \{ \delta_{j,k} \}}{2}$. 
Since $O.T$ is converging, there exists $\gamma > 0$ for $\delta > 0$ 
satisfying Definition~\ref{def:completeOT}, and fair decomposition eventually finds open boxes
such that $\mathbb{S}(f_j)$ and $\mathbb{S}(f_k)$ are separated. 
%\qed
\end{proof}

Limitations for detecting UNSAT occur on \emph{kissing} and \emph{convergent} cases. 
Fig.~\ref{fig:limit} left shows a kissing case 
$x^2 + y^2 < 2^2 \wedge (x-4)^2 + (y-3)^2 < 3^2$ such that 
$\overline{\mathbb{S}(- x^2 - y^2 + 2^2)} \cap \overline{\mathbb{S}(- (x-4)^2 - (y-3)^2 + 3^2)} 
= \{(x,y) \mid (1.6, 1.2)\}$. 
Thus, there are no coverings to separate them. 
%$x^2 + y^2 < 2^2$ and $(x-4)^2 + (y-3)^2 < 3^2$. 
%
Fig. \ref{fig:limit} right shows a convergent case 
$y > x + \frac{1}{x} \wedge y < x \wedge x > 0$, which is equivalent to 
$xy > x^2 + x \wedge y < x \wedge x > 0$. 
%The open box is $(0,\infty) \times (0,\infty)$ and 
There are no finite coverings to separate them. 
%$y > x + \frac{1}{x}$ and $y < x$ for $x > 0$. 

\begin{figure}[ht]
%\begin{minipage}[b]{1.0\linewidth}
\centering
\begin{tabular}{cc}
\includegraphics[height=1.65in,width=1.7in]{kissing.eps} &
\includegraphics[height=1.65in,width=1.7in]{convergence.eps}
\end{tabular}
\caption{Limitations for proving UNSAT} 
\label{fig:limit} 
%\end{minipage}
\end{figure} 
\end{comment}